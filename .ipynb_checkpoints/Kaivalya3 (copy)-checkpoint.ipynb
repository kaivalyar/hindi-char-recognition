{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage import io, morphology, img_as_bool, segmentation\n",
    "from scipy import ndimage as ndi\n",
    "from scipy.ndimage.morphology import binary_fill_holes\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_shape = (64,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pad_resize(img):\n",
    "    top = int((224 - img.shape[0])/2)\n",
    "    left = int((224 - img.shape[1])/2)\n",
    "    bottom = 224 - img.shape[0] - top\n",
    "    right = 224 - img.shape[1] - left\n",
    "    img = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=255)\n",
    "    img = img/255.\n",
    "    img = cv2.resize(img, img_shape) #KADD\n",
    "    return img\n",
    "\n",
    "def skeletonize(img):\n",
    "    size = np.size(img)\n",
    "    skel = np.zeros(img.shape,np.uint8)\n",
    "    img = cv2.bitwise_not(img)\n",
    "#     element = cv2.getStructuringElement(cv2.MORPH_CROSS,(1,1))\n",
    "#     done = 0\n",
    "#     while( done < 1 ):\n",
    "#         eroded = cv2.erode(img,element)\n",
    "#         temp = cv2.dilate(eroded,element)\n",
    "#         temp = cv2.subtract(img,temp)\n",
    "#         skel = cv2.bitwise_or(skel,temp)\n",
    "#         img = eroded.copy()\n",
    "\n",
    "#         zeros = size - cv2.countNonZero(img)\n",
    "#         if zeros==size:#cv2.countNonZero(img) * 1 >= 0:#\n",
    "#             done += 1\n",
    "#     img = skel\n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    erosion = cv2.erode(img,kernel,iterations = 2)\n",
    "    img = cv2.bitwise_not(erosion)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page7_16_10_2350_2417.png dropped!\n",
      "100 Done\n",
      "page3_6_0_2327_2417.png dropped!\n",
      "page6_1_1_2340_2375_2379.png dropped!\n",
      "200 Done\n",
      "page7_3_0_2319_2366_2367.png dropped!\n",
      "300 Done\n",
      "page0_8_8_2330_2375_2379.png dropped!\n",
      "400 Done\n",
      "page6_10_6_2325_2366_2380.png dropped!\n",
      "page0_9_15_2332_2375_2379.png dropped!\n",
      "500 Done\n",
      "600 Done\n",
      "700 Done\n",
      "page3_18_4_2332_2366_2379.png dropped!\n",
      "page3_12_0_2357_2364_2416.png dropped!\n",
      "800 Done\n",
      "900 Done\n",
      "page7_3_13_2319_2366_2367.png dropped!\n",
      "1000 Done\n",
      "1100 Done\n",
      "1200 Done\n",
      "1300 Done\n",
      "1400 Done\n",
      "page5_7_8_2325_2367_2388.png dropped!\n",
      "1500 Done\n",
      "page2_4_20_2346_2366_2390.png dropped!\n",
      "1600 Done\n",
      "1700 Done\n",
      "1800 Done\n"
     ]
    }
   ],
   "source": [
    "PATH = '../train_images_modified'\n",
    "images = []\n",
    "base_class = []\n",
    "matra_class = []\n",
    "dot_class = []\n",
    "total_class = []\n",
    "for filename in os.listdir(PATH):\n",
    "    if filename.endswith(\".png\"):\n",
    "        img = cv2.imread(os.path.join(PATH,filename),0)\n",
    "        blur = cv2.GaussianBlur(img,(9,9),0)# KADD\n",
    "        a,img = cv2.threshold(blur,127,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)#KEDIT\n",
    "#         kernel = np.ones((5,5),np.uint8)\n",
    "#         img = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
    "#         plt.imshow(img, cmap='gray')\n",
    "#         plt.show()\n",
    "#        img = skeletonize(img)\n",
    "        img = pad_resize(img)\n",
    "        blur = cv2.GaussianBlur(img,(9,9),0)# KADD\n",
    "        char_arr = filename[:-4].split('_')[3:]\n",
    "        if(len(char_arr)>0):\n",
    "            char_arr = [int(i) for i in char_arr]\n",
    "            base = [i for i in char_arr if (i>=2308 and i<=2361) or (i==2384) or (i>=2392 and i<=2401) or (i>=2404 and i!=2416 and i!=2417)]  \n",
    "            matra = [i for i in char_arr if i>=2362 and i<=2391 and i!=2364 and i!=2362]\n",
    "            dot = [i for i in char_arr if i==2306 or i==2416 or i==2362 or i==2364]\n",
    "            if(len(matra)>1 or len(dot)>1 or len(base)>1 or (len(matra)==0 and len(dot)==0 and len(char_arr)==2)):\n",
    "                print(filename+\" dropped!\")\n",
    "            else:\n",
    "                images.append(img)\n",
    "                base_class.append(base[0])\n",
    "                if(len(matra)==1):\n",
    "                    matra_class.append(matra[0])\n",
    "                else:\n",
    "                    matra_class.append(0)\n",
    "\n",
    "                if len(dot)==1:\n",
    "                    if dot[0] == 2364:\n",
    "                        dot_class.append(2)\n",
    "                    else:\n",
    "                        dot_class.append(1)\n",
    "                else:\n",
    "                    dot_class.append(0)\n",
    "\n",
    "                if len(images)%100==0:\n",
    "                    print(\"{} Done\".format(len(images)))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFZfi0g1eNxkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ffad3f56b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1883\n",
      "1883\n"
     ]
    }
   ],
   "source": [
    "plt.imshow(images[10],\"gray\")\n",
    "plt.show()\n",
    "print(len(images))\n",
    "print(len(dot_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2392, 2353, 2384, 2415, 2310, 2414]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(base_class))\n",
    "freq = {i:base_class.count(i) for i in base_class}\n",
    "[i for i in freq.keys() if freq[i]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1883, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "images = np.array(images)\n",
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1883, 53)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(base_class)\n",
    "y_labeled = le.transform(base_class)\n",
    "y_train = np_utils.to_categorical(y_labeled)\n",
    "print(y_train.shape)\n",
    "#print(le)\n",
    "#le.get_params()\n",
    "#for i in range(len(topr)):\n",
    "#    if base_class[i] == 2405:\n",
    "#        print('{} {}'.format(topr[i], base_class[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1883, 64, 64, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train = np.reshape(images,(-1,img_shape[0],img_shape[1],1))\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Conv2D,MaxPooling2D,Flatten\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "base_model = Sequential()\n",
    "\n",
    "base_model.add(Conv2D(16,(3,3),input_shape = (img_shape[0],img_shape[1],1),activation = 'relu'))\n",
    "base_model.add(Conv2D(16,(3,3),activation = 'relu'))\n",
    "base_model.add(MaxPooling2D())\n",
    "base_model.add(Conv2D(32,(3,3),activation = 'relu'))\n",
    "base_model.add(Conv2D(32,(3,3),activation = 'relu'))\n",
    "base_model.add(MaxPooling2D())\n",
    "base_model.add(Conv2D(64,(3,3),activation = 'relu'))\n",
    "base_model.add(Conv2D(64,(3,3),activation = 'relu'))\n",
    "base_model.add(MaxPooling2D())\n",
    "base_model.add(MaxPooling2D())\n",
    "base_model.add(Dropout(0.5))\n",
    "base_model.add(Flatten())\n",
    "base_model.add(Dense(256,activation = 'sigmoid'))\n",
    "base_model.add(Dropout(0.25))\n",
    "base_model.add(Dense(len(set(base_class)),activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 62, 62, 16)        160       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 60, 60, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 28, 28, 32)        4640      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 26, 26, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 9, 9, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 53)                13621     \n",
      "=================================================================\n",
      "Total params: 151,205\n",
      "Trainable params: 151,205\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "def f1_score(theta):\n",
    "    def score(y_true, y_pred):\n",
    "\n",
    "        y_thresh = K.cast(K.greater(y_pred,theta),K.floatx())\n",
    "\n",
    "        true_pos =  K.sum(y_true * y_thresh)\n",
    "        false_pos = K.sum(y_true * (1. - y_thresh))\n",
    "        false_neg = K.sum((1. - y_true) * y_thresh)\n",
    "\n",
    "        precision = true_pos / (true_pos + false_pos)\n",
    "        recall = true_pos / (true_pos + false_neg)\n",
    "        \n",
    "        f1_score_val = 2 * (precision * recall) / (precision + recall)\n",
    "        return f1_score_val\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# augmentation code here ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1318 samples, validate on 565 samples\n",
      "Epoch 1/30\n",
      "1318/1318 [==============================] - 13s 10ms/step - loss: 3.5451 - categorical_accuracy: 0.0569 - val_loss: 3.3721 - val_categorical_accuracy: 0.0991\n",
      "Epoch 2/30\n",
      "1318/1318 [==============================] - 14s 11ms/step - loss: 3.3707 - categorical_accuracy: 0.1062 - val_loss: 3.2744 - val_categorical_accuracy: 0.1770\n",
      "Epoch 3/30\n",
      "1318/1318 [==============================] - 13s 10ms/step - loss: 3.1365 - categorical_accuracy: 0.1912 - val_loss: 3.0685 - val_categorical_accuracy: 0.1841\n",
      "Epoch 4/30\n",
      "1318/1318 [==============================] - 15s 12ms/step - loss: 2.8646 - categorical_accuracy: 0.2572 - val_loss: 2.7825 - val_categorical_accuracy: 0.2442\n",
      "Epoch 5/30\n",
      "1318/1318 [==============================] - 14s 11ms/step - loss: 2.5693 - categorical_accuracy: 0.3331 - val_loss: 2.2934 - val_categorical_accuracy: 0.3982\n",
      "Epoch 6/30\n",
      "1318/1318 [==============================] - 15s 11ms/step - loss: 2.2510 - categorical_accuracy: 0.4211 - val_loss: 2.0754 - val_categorical_accuracy: 0.4460\n",
      "Epoch 7/30\n",
      "1318/1318 [==============================] - 15s 12ms/step - loss: 1.9431 - categorical_accuracy: 0.5023 - val_loss: 1.7224 - val_categorical_accuracy: 0.5575\n",
      "Epoch 8/30\n",
      " 512/1318 [==========>...................] - ETA: 9s - loss: 1.8925 - categorical_accuracy: 0.5020 "
     ]
    }
   ],
   "source": [
    "base_model.fit(x_train,y_train,epochs=30,batch_size=32,validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_adam = keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "base_model.compile(optimizer=new_adam,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['categorical_accuracy'])\n",
    "base_model.fit(x_train,y_train,epochs=10,batch_size=32,validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_adam = keras.optimizers.Adam(lr=0.00005, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "base_model.compile(optimizer=new_adam,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['categorical_accuracy'])\n",
    "base_model.fit(x_train,y_train,epochs=30,batch_size=32,validation_split=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "y_pred = base_model.predict_classes(x_train)\n",
    "y_original = np.argmax(y_train, axis=1)\n",
    "\n",
    "cm = confusion_matrix(y_original, y_pred)\n",
    "print('confusion matrix for {} features (base):'.format(cm.shape))\n",
    "print(cm)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,20))\n",
    "sns.heatmap(cm, cmap=sns.light_palette('purple', n_colors=500, as_cmap=True), annot=True, linewidths = 5, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DOT CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_dot = np_utils.to_categorical(dot_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dot_model = Sequential()\n",
    "\n",
    "dot_model.add(Conv2D(16,(3,3),input_shape = (img_shape[0],img_shape[1],1),activation = 'relu'))\n",
    "dot_model.add(Conv2D(16,(3,3),activation = 'relu'))\n",
    "dot_model.add(MaxPooling2D())\n",
    "dot_model.add(Conv2D(32,(3,3),activation = 'relu'))\n",
    "dot_model.add(Conv2D(32,(3,3),activation = 'relu'))\n",
    "dot_model.add(MaxPooling2D())\n",
    "dot_model.add(Conv2D(64,(3,3),activation = 'relu'))\n",
    "dot_model.add(Conv2D(64,(3,3),activation = 'relu'))\n",
    "dot_model.add(MaxPooling2D())\n",
    "dot_model.add(Flatten())\n",
    "dot_model.add(Dense(64,activation = 'sigmoid'))\n",
    "dot_model.add(Dropout(0.5))\n",
    "dot_model.add(Dense(len(set(dot_class)),activation = 'softmax'))\n",
    "\n",
    "dot_model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['categorical_accuracy'])\n",
    "\n",
    "dot_model.fit(x_train,y_train_dot,epochs=10,batch_size=32,validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_adam = keras.optimizers.Adam(lr=0.0005, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "dot_model.compile(optimizer=new_adam,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['categorical_accuracy'])\n",
    "dot_model.fit(x_train,y_train_dot,epochs=5,batch_size=64,validation_split=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "y_pred = dot_model.predict_classes(x_train)\n",
    "y_original = np.argmax(y_train_dot, axis=1)\n",
    "\n",
    "cm = confusion_matrix(y_original, y_pred)\n",
    "print('confusion matrix for {} features (dot):'.format(cm.shape))\n",
    "print(cm)\n",
    "\n",
    "#fig, ax = plt.subplots(figsize=(20,20))\n",
    "sns.heatmap(cm, cmap=sns.light_palette('purple', n_colors=500, as_cmap=True), annot=True, linewidths = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MATRA CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "le_matra = LabelEncoder()\n",
    "le_matra.fit(matra_class)\n",
    "y_labeled_matra = le_matra.transform(matra_class)\n",
    "y_train_matra = np_utils.to_categorical(y_labeled_matra)\n",
    "\n",
    "print(y_train_matra.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "matra_model = Sequential()\n",
    "\n",
    "matra_model.add(Conv2D(16,(3,3),input_shape = (img_shape[0],img_shape[1],1),activation = 'relu'))\n",
    "matra_model.add(Conv2D(16,(3,3),activation = 'relu'))\n",
    "matra_model.add(MaxPooling2D())\n",
    "matra_model.add(Conv2D(32,(3,3),activation = 'relu'))\n",
    "matra_model.add(Conv2D(32,(3,3),activation = 'relu'))\n",
    "matra_model.add(MaxPooling2D())\n",
    "matra_model.add(Conv2D(64,(3,3),activation = 'relu'))\n",
    "matra_model.add(Conv2D(64,(3,3),activation = 'relu'))\n",
    "matra_model.add(MaxPooling2D())\n",
    "matra_model.add(MaxPooling2D())\n",
    "matra_model.add(Dropout(0.5))\n",
    "matra_model.add(Flatten())\n",
    "matra_model.add(Dense(128,activation = 'sigmoid'))\n",
    "matra_model.add(Dropout(0.25))\n",
    "matra_model.add(Dense(len(set(matra_class)),activation = 'softmax'))\n",
    "\n",
    "matra_model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['categorical_accuracy'])\n",
    "\n",
    "matra_model.fit(x_train,y_train_matra,epochs=35,batch_size=32,validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_adam = keras.optimizers.Adam(lr=0.00005, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "matra_model.compile(optimizer=new_adam,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['categorical_accuracy'])\n",
    "matra_model.fit(x_train,y_train_matra,epochs=20,batch_size=32,validation_split=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "y_pred = matra_model.predict_classes(x_train)\n",
    "y_original = np.argmax(y_train_matra, axis=1)\n",
    "\n",
    "cm = confusion_matrix(y_original, y_pred)\n",
    "print('confusion matrix for {} features (matra):'.format(cm.shape))\n",
    "print(cm)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,20))\n",
    "sns.heatmap(cm, cmap=sns.light_palette('purple', n_colors=500, as_cmap=True), annot=True, linewidths = 5, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dumping Models to Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dot_model.save('models/dot_model4k.model')\n",
    "matra_model.save('models/matra_model4k.model')\n",
    "base_model.save('models/base_model4k.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "dot_model2 = load_model('models/dot_model4k.model')\n",
    "matra_model2 = load_model('models/matra_model4k.model')\n",
    "base_model2 = load_model('models/base_model4k.model')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Half Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
