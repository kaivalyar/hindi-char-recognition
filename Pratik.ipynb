{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage import io, morphology, img_as_bool, segmentation\n",
    "from scipy import ndimage as ndi\n",
    "from scipy.ndimage.morphology import binary_fill_holes\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pad_resize(img):\n",
    "    top = int((224 - img.shape[0])/2)\n",
    "    left = int((224 - img.shape[1])/2)\n",
    "    bottom = 224 - img.shape[0] - top\n",
    "    right = 224 - img.shape[1] - left\n",
    "    img = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=255)\n",
    "    img = img/255.\n",
    "    img = cv2.resize(img, (64,64)) #KADD\n",
    "    return img\n",
    "\n",
    "def skeletonize(img):\n",
    "    size = np.size(img)\n",
    "    skel = np.zeros(img.shape,np.uint8)\n",
    "    img = cv2.bitwise_not(img)\n",
    "#     element = cv2.getStructuringElement(cv2.MORPH_CROSS,(1,1))\n",
    "#     done = 0\n",
    "#     while( done < 1 ):\n",
    "#         eroded = cv2.erode(img,element)\n",
    "#         temp = cv2.dilate(eroded,element)\n",
    "#         temp = cv2.subtract(img,temp)\n",
    "#         skel = cv2.bitwise_or(skel,temp)\n",
    "#         img = eroded.copy()\n",
    "\n",
    "#         zeros = size - cv2.countNonZero(img)\n",
    "#         if zeros==size:#cv2.countNonZero(img) * 1 >= 0:#\n",
    "#             done += 1\n",
    "#     img = skel\n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    erosion = cv2.erode(img,kernel,iterations = 2)\n",
    "    img = cv2.bitwise_not(erosion)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 Done\n",
      "200 Done\n",
      "300 Done\n",
      "400 Done\n",
      "500 Done\n",
      "600 Done\n",
      "700 Done\n",
      "800 Done\n",
      "900 Done\n",
      "1000 Done\n",
      "1100 Done\n",
      "1200 Done\n",
      "1300 Done\n",
      "1400 Done\n",
      "1500 Done\n",
      "1600 Done\n",
      "1700 Done\n",
      "1800 Done\n"
     ]
    }
   ],
   "source": [
    "PATH = '../train_images_modified'\n",
    "images = []\n",
    "base_class = []\n",
    "matra_class = []\n",
    "dot_class = []\n",
    "total_class = []\n",
    "half_char_class = []\n",
    "\n",
    "for filename in os.listdir(PATH):\n",
    "    if filename.endswith(\".png\"):\n",
    "        img = cv2.imread(os.path.join(PATH,filename),0)\n",
    "        blur = cv2.GaussianBlur(img,(9,9),0)# KADD\n",
    "        a,img = cv2.threshold(blur,127,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)#KEDIT\n",
    "#         plt.imshow(img, cmap='gray')\n",
    "#         plt.show()\n",
    "# #         kernel = np.ones((5,5),np.uint8)\n",
    "#         img = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
    "#         plt.imshow(img, cmap='gray')\n",
    "#         plt.show()\n",
    "        #img = skeletonize(img)\n",
    "        img = pad_resize(img)\n",
    "        char_arr = filename[:-4].split('_')[3:]\n",
    "        if(len(char_arr)>0):\n",
    "            images.append(img)\n",
    "            char_arr = [int(i) for i in char_arr]\n",
    "            total_class.append(char_arr)\n",
    "            base = [i for i in char_arr if (i>=2308 and i<=2361) or (i==2384) or (i>=2392 and i<=2401) or (i>=2404 and i!=2416 and i!=2417)]  \n",
    "            base_class.append(base[0])\n",
    "            dot = [i for i in char_arr if i in [2306,2416,2417]]\n",
    "            if(len(dot)>0):\n",
    "                dot_class.append(1)\n",
    "            else:\n",
    "                dot_class.append(0)\n",
    "            matra = [i for i in char_arr if (i>=2304 and i<=2307) or (i>=2362 and i<=2380) or (i>=2382 and i<=2383) or (i>=2385 and i<=2391) or (i>=2402 and i<=2403)]\n",
    "            if(len(matra)>0):\n",
    "                matra_class.append(matra[0])\n",
    "            else:\n",
    "                matra_class.append(0)\n",
    "            half_char = [i for i in char_arr if (i==2381)]\n",
    "            if(len(half_char)>0):\n",
    "                half_char_class.append(1)\n",
    "            else:\n",
    "                half_char_class.append(0)\n",
    "#             if(len(char_arr)>1):          \n",
    "#                 matra_class.append(char_arr[1:])\n",
    "            if len(images)%100==0:\n",
    "                print(\"{} Done\".format(len(images)))\n",
    "            \n",
    "# print(len(images))\n",
    "# print(len(char_class))\n",
    "# print(images[0])\n",
    "# print(char_class[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1f92bade10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1895\n"
     ]
    }
   ],
   "source": [
    "plt.imshow(images[102],\"gray\")\n",
    "plt.show()\n",
    "print(len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(model.predict(X_train[0].reshape(-1,64,64,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "half_images = []\n",
    "for image in images:\n",
    "    half_im = np.hsplit(image,2)\n",
    "    half_images.append(half_im[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJIAAAD8CAYAAACchf2kAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n2ztiZK1+3x0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1fcb21cb38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(half_images[6],\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = plt.imread('ok.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.42352942,  0.34901962,  0.22352941,  1.        ],\n",
       "        [ 0.43529412,  0.36078432,  0.24313726,  1.        ],\n",
       "        [ 0.45490196,  0.3764706 ,  0.27058825,  1.        ],\n",
       "        ..., \n",
       "        [ 0.13333334,  0.12156863,  0.15686275,  1.        ],\n",
       "        [ 0.14901961,  0.12941177,  0.15686275,  1.        ],\n",
       "        [ 0.18431373,  0.16470589,  0.1882353 ,  1.        ]],\n",
       "\n",
       "       [[ 0.45490196,  0.38039216,  0.25490198,  1.        ],\n",
       "        [ 0.44313726,  0.36862746,  0.25098041,  1.        ],\n",
       "        [ 0.43921569,  0.36078432,  0.25490198,  1.        ],\n",
       "        ..., \n",
       "        [ 0.14117648,  0.12941177,  0.16470589,  1.        ],\n",
       "        [ 0.12941177,  0.10980392,  0.13725491,  1.        ],\n",
       "        [ 0.13725491,  0.11764706,  0.14117648,  1.        ]],\n",
       "\n",
       "       [[ 0.46666667,  0.39215687,  0.27450982,  1.        ],\n",
       "        [ 0.44313726,  0.36862746,  0.25098041,  1.        ],\n",
       "        [ 0.42352942,  0.34901962,  0.23137255,  1.        ],\n",
       "        ..., \n",
       "        [ 0.14509805,  0.14117648,  0.16470589,  1.        ],\n",
       "        [ 0.13725491,  0.13333334,  0.15294118,  1.        ],\n",
       "        [ 0.13725491,  0.13725491,  0.14509805,  1.        ]],\n",
       "\n",
       "       ..., \n",
       "       [[ 0.40784314,  0.35294119,  0.25098041,  1.        ],\n",
       "        [ 0.41568628,  0.35294119,  0.25490198,  1.        ],\n",
       "        [ 0.44705883,  0.38431373,  0.28235295,  1.        ],\n",
       "        ..., \n",
       "        [ 0.4509804 ,  0.35686275,  0.26274511,  1.        ],\n",
       "        [ 0.47058824,  0.3764706 ,  0.28235295,  1.        ],\n",
       "        [ 0.48235294,  0.3882353 ,  0.29411766,  1.        ]],\n",
       "\n",
       "       [[ 0.41960785,  0.36470589,  0.26274511,  1.        ],\n",
       "        [ 0.41960785,  0.35686275,  0.25882354,  1.        ],\n",
       "        [ 0.43529412,  0.37254903,  0.27058825,  1.        ],\n",
       "        ..., \n",
       "        [ 0.4509804 ,  0.35686275,  0.26274511,  1.        ],\n",
       "        [ 0.47450981,  0.38039216,  0.28627452,  1.        ],\n",
       "        [ 0.47843137,  0.38431373,  0.29019609,  1.        ]],\n",
       "\n",
       "       [[ 0.43137255,  0.3882353 ,  0.30980393,  1.        ],\n",
       "        [ 0.41176471,  0.36470589,  0.27843139,  1.        ],\n",
       "        [ 0.41568628,  0.35686275,  0.27450982,  1.        ],\n",
       "        ..., \n",
       "        [ 0.47058824,  0.3764706 ,  0.28235295,  1.        ],\n",
       "        [ 0.48235294,  0.3882353 ,  0.29411766,  1.        ],\n",
       "        [ 0.47843137,  0.38431373,  0.29019609,  1.        ]]], dtype=float32)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(base_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2368,\n",
       " 2306,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2366,\n",
       " 0,\n",
       " 2366,\n",
       " 0,\n",
       " 2376,\n",
       " 2367,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2370,\n",
       " 2375,\n",
       " 2375,\n",
       " 0,\n",
       " 2367,\n",
       " 0,\n",
       " 2367,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2376,\n",
       " 0,\n",
       " 2366,\n",
       " 2375,\n",
       " 0,\n",
       " 2380,\n",
       " 2366,\n",
       " 0,\n",
       " 2366,\n",
       " 0,\n",
       " 2366,\n",
       " 2379,\n",
       " 2375,\n",
       " 2376,\n",
       " 2367,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2380,\n",
       " 2367,\n",
       " 0,\n",
       " 0,\n",
       " 2380,\n",
       " 0,\n",
       " 0,\n",
       " 2306,\n",
       " 0,\n",
       " 0,\n",
       " 2380,\n",
       " 0,\n",
       " 2380,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2367,\n",
       " 2368,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2376,\n",
       " 0,\n",
       " 0,\n",
       " 2366,\n",
       " 0,\n",
       " 0,\n",
       " 2375,\n",
       " 2366,\n",
       " 2370,\n",
       " 2368,\n",
       " 0,\n",
       " 2370,\n",
       " 2367,\n",
       " 0,\n",
       " 2366,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2306,\n",
       " 2367,\n",
       " 2366,\n",
       " 0,\n",
       " 2375,\n",
       " 2366,\n",
       " 0,\n",
       " 0,\n",
       " 2306,\n",
       " 2306,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2379,\n",
       " 2376,\n",
       " 2368,\n",
       " 0,\n",
       " 2379,\n",
       " 2368,\n",
       " 2367,\n",
       " 2368,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2366,\n",
       " 0,\n",
       " 2367,\n",
       " 2306,\n",
       " 2369,\n",
       " 2366,\n",
       " 2368,\n",
       " 2376,\n",
       " 2366,\n",
       " 2370,\n",
       " 2370,\n",
       " 2363,\n",
       " 0,\n",
       " 0,\n",
       " 2366,\n",
       " 2368,\n",
       " 0,\n",
       " 0,\n",
       " 2366,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2369,\n",
       " 0,\n",
       " 0,\n",
       " 2367,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2366,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2367,\n",
       " 2367,\n",
       " 2366,\n",
       " 0,\n",
       " 2366,\n",
       " 2366,\n",
       " 0,\n",
       " 2366,\n",
       " 2379,\n",
       " 0,\n",
       " 2366,\n",
       " 0,\n",
       " 2366,\n",
       " 2366,\n",
       " 2367,\n",
       " 2366,\n",
       " 2368,\n",
       " 2366,\n",
       " 2366,\n",
       " 0,\n",
       " 0,\n",
       " 2375,\n",
       " 2375,\n",
       " 2306,\n",
       " 2367,\n",
       " 2366,\n",
       " 0,\n",
       " 2375,\n",
       " 2366,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2368,\n",
       " 2376,\n",
       " 2306,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2369,\n",
       " 0,\n",
       " 0,\n",
       " 2379,\n",
       " 0,\n",
       " 0,\n",
       " 2367,\n",
       " 2366,\n",
       " 2376,\n",
       " 2366,\n",
       " 0,\n",
       " 2368,\n",
       " 0,\n",
       " 2306,\n",
       " 2366,\n",
       " 0,\n",
       " 2379,\n",
       " 2306,\n",
       " 0,\n",
       " 0,\n",
       " 2368,\n",
       " 0,\n",
       " 0,\n",
       " 2375,\n",
       " 0,\n",
       " 2306,\n",
       " 0,\n",
       " 0,\n",
       " 2379,\n",
       " 2375,\n",
       " 2376,\n",
       " 2366,\n",
       " 2364,\n",
       " 0,\n",
       " 0,\n",
       " 2376,\n",
       " 0,\n",
       " 0,\n",
       " 2379,\n",
       " 2376,\n",
       " 0,\n",
       " 2366,\n",
       " 0,\n",
       " 2380,\n",
       " 2366,\n",
       " 2366,\n",
       " 2375,\n",
       " 2376,\n",
       " 0,\n",
       " 2379,\n",
       " 0,\n",
       " 2366,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2370,\n",
       " 0,\n",
       " 2366,\n",
       " 2375,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2375,\n",
       " 0,\n",
       " 0,\n",
       " 2379,\n",
       " 2367,\n",
       " 2379,\n",
       " 0,\n",
       " 2379,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2367,\n",
       " 2376,\n",
       " 2367,\n",
       " 0,\n",
       " 0,\n",
       " 2375,\n",
       " 0,\n",
       " 2367,\n",
       " 0,\n",
       " 0,\n",
       " 2379,\n",
       " 2367,\n",
       " 2380,\n",
       " 2306,\n",
       " 2366,\n",
       " 0,\n",
       " 0,\n",
       " 2366,\n",
       " 2306,\n",
       " 0,\n",
       " 2375,\n",
       " 2367,\n",
       " 2366,\n",
       " 2306,\n",
       " 2376,\n",
       " 0,\n",
       " 0,\n",
       " 2367,\n",
       " 0,\n",
       " 2306,\n",
       " 2306,\n",
       " 2366,\n",
       " 2369,\n",
       " 0,\n",
       " 2367,\n",
       " 0,\n",
       " 0,\n",
       " 2376,\n",
       " 2368,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2375,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2367,\n",
       " 2367,\n",
       " 2375,\n",
       " 2366,\n",
       " 2367,\n",
       " 0,\n",
       " 0,\n",
       " 2375,\n",
       " 2379,\n",
       " 2375,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2367,\n",
       " 2366,\n",
       " 2366,\n",
       " 0,\n",
       " 0,\n",
       " 2366,\n",
       " 2375,\n",
       " 2368,\n",
       " 0,\n",
       " 2368,\n",
       " 2369,\n",
       " 0,\n",
       " 0,\n",
       " 2366,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2366,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2366,\n",
       " 2366,\n",
       " 2368,\n",
       " 0,\n",
       " 0,\n",
       " 2375,\n",
       " 2306,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2379,\n",
       " 2368,\n",
       " 2364,\n",
       " 0,\n",
       " 0,\n",
       " 2376,\n",
       " 0,\n",
       " 2375,\n",
       " 0,\n",
       " 0,\n",
       " 2306,\n",
       " 2367,\n",
       " 2367,\n",
       " 0,\n",
       " 0,\n",
       " 2364,\n",
       " 2306,\n",
       " 0,\n",
       " 0,\n",
       " 2367,\n",
       " 2367,\n",
       " 0,\n",
       " 2366,\n",
       " 0,\n",
       " 0,\n",
       " 2380,\n",
       " 2379,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2368,\n",
       " 2367,\n",
       " 2306,\n",
       " 2367,\n",
       " 2375,\n",
       " 2368,\n",
       " 2366,\n",
       " 0,\n",
       " 2367,\n",
       " 2380,\n",
       " 0,\n",
       " 2390,\n",
       " 2375,\n",
       " 2368,\n",
       " 0,\n",
       " 2380,\n",
       " 2306,\n",
       " 0,\n",
       " 2376,\n",
       " 2367,\n",
       " 2306,\n",
       " 0,\n",
       " 2368,\n",
       " 2370,\n",
       " 0,\n",
       " 2380,\n",
       " 2369,\n",
       " 2375,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2380,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2375,\n",
       " 0,\n",
       " 0,\n",
       " 2366,\n",
       " 0,\n",
       " 2379,\n",
       " 2366,\n",
       " 0,\n",
       " 2306,\n",
       " 2375,\n",
       " 0,\n",
       " 2306,\n",
       " 2367,\n",
       " 0,\n",
       " 0,\n",
       " 2366,\n",
       " 2366,\n",
       " 2366,\n",
       " 2306,\n",
       " 2366,\n",
       " 2306,\n",
       " 0,\n",
       " 0,\n",
       " 2368,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2376,\n",
       " 2366,\n",
       " 2306,\n",
       " 2368,\n",
       " 0,\n",
       " 0,\n",
       " 2376,\n",
       " 2380,\n",
       " 2367,\n",
       " 2306,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2306,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2375,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2362,\n",
       " 2367,\n",
       " 2380,\n",
       " 0,\n",
       " 2380,\n",
       " 0,\n",
       " 0,\n",
       " 2366,\n",
       " 2369,\n",
       " 2382,\n",
       " 0,\n",
       " 2367,\n",
       " 0,\n",
       " 2367,\n",
       " 2366,\n",
       " 2366,\n",
       " 2370,\n",
       " 0,\n",
       " 2306,\n",
       " 2366,\n",
       " 0,\n",
       " 0,\n",
       " 2368,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2368,\n",
       " 0,\n",
       " 2376,\n",
       " 2367,\n",
       " 2367,\n",
       " 0,\n",
       " 2367,\n",
       " 0,\n",
       " 2375,\n",
       " 2366,\n",
       " 0,\n",
       " 2367,\n",
       " 0,\n",
       " 0,\n",
       " 2370,\n",
       " 2367,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2367,\n",
       " 2366,\n",
       " 2306,\n",
       " 2375,\n",
       " 0,\n",
       " 0,\n",
       " 2306,\n",
       " 0,\n",
       " 0,\n",
       " 2376,\n",
       " 2380,\n",
       " 0,\n",
       " 2306,\n",
       " 2369,\n",
       " 0,\n",
       " 2376,\n",
       " 2366,\n",
       " 0,\n",
       " 0,\n",
       " 2375,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2366,\n",
       " 0,\n",
       " 2376,\n",
       " 0,\n",
       " 2370,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2368,\n",
       " 2366,\n",
       " 0,\n",
       " 0,\n",
       " 2367,\n",
       " 0,\n",
       " 2366,\n",
       " 2368,\n",
       " 2367,\n",
       " 0,\n",
       " 0,\n",
       " 2366,\n",
       " 2367,\n",
       " 2379,\n",
       " 2380,\n",
       " 2366,\n",
       " 0,\n",
       " 2366,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2366,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2368,\n",
       " 2368,\n",
       " 0,\n",
       " 2364,\n",
       " 2368,\n",
       " 2306,\n",
       " 2367,\n",
       " 0,\n",
       " 2368,\n",
       " 2375,\n",
       " 2379,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2367,\n",
       " 2368,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2367,\n",
       " 2367,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2379,\n",
       " 2369,\n",
       " 2367,\n",
       " 2366,\n",
       " 0,\n",
       " 2363,\n",
       " 2380,\n",
       " 0,\n",
       " 0,\n",
       " 2306,\n",
       " 0,\n",
       " 0,\n",
       " 2380,\n",
       " 0,\n",
       " 2367,\n",
       " 0,\n",
       " 2366,\n",
       " 0,\n",
       " 2366,\n",
       " 2367,\n",
       " 2366,\n",
       " 2369,\n",
       " 2366,\n",
       " 2306,\n",
       " 2375,\n",
       " 2366,\n",
       " 2375,\n",
       " 2366,\n",
       " 2367,\n",
       " 2367,\n",
       " 2375,\n",
       " 2367,\n",
       " 2366,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2375,\n",
       " 2367,\n",
       " 2366,\n",
       " 2366,\n",
       " 2379,\n",
       " 0,\n",
       " 2379,\n",
       " 2366,\n",
       " 2366,\n",
       " 2367,\n",
       " 2379,\n",
       " 0,\n",
       " 0,\n",
       " 2366,\n",
       " 0,\n",
       " 2375,\n",
       " 2364,\n",
       " 0,\n",
       " 2376,\n",
       " 2376,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2369,\n",
       " 2366,\n",
       " 0,\n",
       " 0,\n",
       " 2306,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2366,\n",
       " 2368,\n",
       " 0,\n",
       " 0,\n",
       " 2368,\n",
       " 2370,\n",
       " 2368,\n",
       " 0,\n",
       " 0,\n",
       " 2367,\n",
       " 2368,\n",
       " 2380,\n",
       " 2366,\n",
       " 2366,\n",
       " 2368,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2375,\n",
       " 0,\n",
       " 2366,\n",
       " 0,\n",
       " 2366,\n",
       " 2366,\n",
       " 2366,\n",
       " 0,\n",
       " 2306,\n",
       " 2367,\n",
       " 2366,\n",
       " 0,\n",
       " 0,\n",
       " 2366,\n",
       " 2367,\n",
       " 2375,\n",
       " 2375,\n",
       " 2306,\n",
       " 2368,\n",
       " 2380,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2379,\n",
       " 2366,\n",
       " 2375,\n",
       " 0,\n",
       " 2367,\n",
       " 2367,\n",
       " 0,\n",
       " 2366,\n",
       " 0,\n",
       " 2366,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2368,\n",
       " 2375,\n",
       " 0,\n",
       " 0,\n",
       " 2376,\n",
       " 2306,\n",
       " 2375,\n",
       " 0,\n",
       " 2375,\n",
       " 2367,\n",
       " 2368,\n",
       " 2366,\n",
       " 2379,\n",
       " 2366,\n",
       " 2375,\n",
       " 0,\n",
       " 2367,\n",
       " 2367,\n",
       " 0,\n",
       " 2306,\n",
       " 2306,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2379,\n",
       " 0,\n",
       " 2366,\n",
       " 0,\n",
       " 0,\n",
       " 2375,\n",
       " 2379,\n",
       " 0,\n",
       " 2367,\n",
       " 2362,\n",
       " 2366,\n",
       " 0,\n",
       " 2367,\n",
       " 2366,\n",
       " 2366,\n",
       " 2375,\n",
       " 0,\n",
       " 0,\n",
       " 2367,\n",
       " 0,\n",
       " 2367,\n",
       " 2366,\n",
       " 2366,\n",
       " 0,\n",
       " 2366,\n",
       " 2376,\n",
       " 0,\n",
       " 2376,\n",
       " 0,\n",
       " 2306,\n",
       " 0,\n",
       " 2380,\n",
       " 0,\n",
       " 2366,\n",
       " 2379,\n",
       " 2379,\n",
       " 2370,\n",
       " 2368,\n",
       " 2379,\n",
       " 0,\n",
       " 2367,\n",
       " 0,\n",
       " 2379,\n",
       " 2366,\n",
       " 2362,\n",
       " 0,\n",
       " 2376,\n",
       " 2367,\n",
       " 2306,\n",
       " 0,\n",
       " 2366,\n",
       " 0,\n",
       " 0,\n",
       " 2367,\n",
       " 0,\n",
       " 2367,\n",
       " 0,\n",
       " 2366,\n",
       " 0,\n",
       " 2375,\n",
       " 0,\n",
       " 0,\n",
       " 2368,\n",
       " 2368,\n",
       " 2376,\n",
       " 2366,\n",
       " 2306,\n",
       " 2367,\n",
       " 2367,\n",
       " 0,\n",
       " 2366,\n",
       " 2367,\n",
       " 2380,\n",
       " 0,\n",
       " 2367,\n",
       " 0,\n",
       " 2375,\n",
       " 2368,\n",
       " 2367,\n",
       " 2366,\n",
       " 2368,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2366,\n",
       " 2366,\n",
       " 0,\n",
       " 2366,\n",
       " 2369,\n",
       " 0,\n",
       " 0,\n",
       " 2380,\n",
       " 0,\n",
       " 2366,\n",
       " 2368,\n",
       " 0,\n",
       " 0,\n",
       " 2367,\n",
       " 2375,\n",
       " 2368,\n",
       " 0,\n",
       " 2366,\n",
       " 0,\n",
       " 2376,\n",
       " 0,\n",
       " 0,\n",
       " 2372,\n",
       " 2306,\n",
       " 2368,\n",
       " 0,\n",
       " 2370,\n",
       " 2366,\n",
       " 0,\n",
       " 2366,\n",
       " 2367,\n",
       " 2369,\n",
       " 2368,\n",
       " 0,\n",
       " 0,\n",
       " 2366,\n",
       " 2366,\n",
       " 0,\n",
       " 2387,\n",
       " 2367,\n",
       " 2366,\n",
       " 2363,\n",
       " 2367,\n",
       " 0,\n",
       " 2366,\n",
       " 2367,\n",
       " 2367,\n",
       " 2366,\n",
       " 0,\n",
       " 0,\n",
       " 2306,\n",
       " 0,\n",
       " 2367,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2367,\n",
       " 0,\n",
       " 2366,\n",
       " 2367,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2367,\n",
       " 2367,\n",
       " 2366,\n",
       " 2367,\n",
       " 2366,\n",
       " 2370,\n",
       " 2380,\n",
       " 2364,\n",
       " 2366,\n",
       " 2366,\n",
       " 2375,\n",
       " 0,\n",
       " 2375,\n",
       " 2369,\n",
       " 2368,\n",
       " 0,\n",
       " 2375,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2368,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2375,\n",
       " 2366,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2379,\n",
       " 0,\n",
       " 0,\n",
       " 2368,\n",
       " 2366,\n",
       " 0,\n",
       " 2366,\n",
       " 0,\n",
       " 2366,\n",
       " 2306,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2306,\n",
       " 2364,\n",
       " 2366,\n",
       " 2375,\n",
       " 2379,\n",
       " 2306,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2375,\n",
       " 2367,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2375,\n",
       " 2367,\n",
       " 0,\n",
       " 2376,\n",
       " 2366,\n",
       " 2379,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2366,\n",
       " 0,\n",
       " 0,\n",
       " 2368,\n",
       " 2375,\n",
       " 0,\n",
       " 0,\n",
       " 2368,\n",
       " 2368,\n",
       " 2367,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matra_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images = np.array(images)\n",
    "X = np.reshape(np.array(images), (-1, 64*64))\n",
    "y = np.array(base_class)\n",
    "\n",
    "df = pd.DataFrame(X, y)\n",
    "df['LABEL'] = df.index\n",
    "\n",
    "df_no_label = df.drop(columns='LABEL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2407"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = np.reshape(X[0],(-1,64,64,1))\n",
    "np.argmax(model.predict(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>4086</th>\n",
       "      <th>4087</th>\n",
       "      <th>4088</th>\n",
       "      <th>4089</th>\n",
       "      <th>4090</th>\n",
       "      <th>4091</th>\n",
       "      <th>4092</th>\n",
       "      <th>4093</th>\n",
       "      <th>4094</th>\n",
       "      <th>4095</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2325</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2350</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2347</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2360</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2312</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 4096 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1     2     3     4     5     6     7     8     9     ...   4086  \\\n",
       "2325   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0  ...    1.0   \n",
       "2350   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0  ...    1.0   \n",
       "2347   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0  ...    1.0   \n",
       "2360   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0  ...    1.0   \n",
       "2312   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0  ...    1.0   \n",
       "\n",
       "      4087  4088  4089  4090  4091  4092  4093  4094  4095  \n",
       "2325   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0  \n",
       "2350   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0  \n",
       "2347   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0  \n",
       "2360   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0  \n",
       "2312   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0  \n",
       "\n",
       "[5 rows x 4096 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(base_class)\n",
    "y_labeled = le.transform(base_class)\n",
    "y_train = np_utils.to_categorical(y_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dict = { i:le.classes_[i] for i in range(len(le.classes_))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le_dot.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1895, 53)\n",
      "(1895, 64, 64, 1)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "X_train = np.reshape(images,(-1,64,64,1))\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>4087</th>\n",
       "      <th>4088</th>\n",
       "      <th>4089</th>\n",
       "      <th>4090</th>\n",
       "      <th>4091</th>\n",
       "      <th>4092</th>\n",
       "      <th>4093</th>\n",
       "      <th>4094</th>\n",
       "      <th>4095</th>\n",
       "      <th>LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2325</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2350</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2347</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2360</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2312</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 4097 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0    1    2    3    4    5    6    7    8    9  ...    4087  4088  \\\n",
       "2325  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...     1.0   1.0   \n",
       "2350  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...     1.0   1.0   \n",
       "2347  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...     1.0   1.0   \n",
       "2360  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...     1.0   1.0   \n",
       "2312  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...     1.0   1.0   \n",
       "\n",
       "      4089  4090  4091  4092  4093  4094  4095  LABEL  \n",
       "2325   1.0   1.0   1.0   1.0   1.0   1.0   1.0   2325  \n",
       "2350   1.0   1.0   1.0   1.0   1.0   1.0   1.0   2350  \n",
       "2347   1.0   1.0   1.0   1.0   1.0   1.0   1.0   2347  \n",
       "2360   1.0   1.0   1.0   1.0   1.0   1.0   1.0   2360  \n",
       "2312   1.0   1.0   1.0   1.0   1.0   1.0   1.0   2312  \n",
       "\n",
       "[5 rows x 4097 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consonant Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Conv2D,Flatten,MaxPooling2D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(16,(3,3),input_shape=(X_train[0].shape),activation = 'relu'))\n",
    "model.add(Conv2D(16,(3,3),activation = 'relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(32,(2,2),activation = 'relu'))\n",
    "model.add(Conv2D(32,(2,2),activation = 'relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(64,(2,2),activation = 'relu'))\n",
    "model.add(Conv2D(64,(2,2),activation = 'relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256,activation = 'sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(set(base_class)),activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 62, 62, 16)        160       \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 60, 60, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 29, 29, 32)        2080      \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 28, 28, 32)        4128      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 13, 13, 64)        8256      \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 12, 12, 64)        16448     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               590080    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 53)                13621     \n",
      "=================================================================\n",
      "Total params: 637,093\n",
      "Trainable params: 637,093\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "def f1_score(theta):\n",
    "    def score(y_true, y_pred):\n",
    "\n",
    "        y_thresh = K.cast(K.greater(y_pred,theta),K.floatx())\n",
    "\n",
    "        true_pos =  K.sum(y_true * y_thresh)\n",
    "        false_pos = K.sum(y_true * (1. - y_thresh))\n",
    "        false_neg = K.sum((1. - y_true) * y_thresh)\n",
    "\n",
    "        precision = true_pos / (true_pos + false_pos)\n",
    "        recall = true_pos / (true_pos + false_neg)\n",
    "        \n",
    "        f1_score_val = 2 * (precision * recall) / (precision + recall)\n",
    "        return f1_score_val\n",
    "    return score\n",
    "\n",
    "def custom_metric(y_true, y_pred):\n",
    "    return K.cast(K.equal(y_true,\n",
    "                          K.round(y_pred)),\n",
    "                  K.floatx())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=[f1_score(theta=0.5), 'categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "checkpointer = ModelCheckpoint(filepath='consonantweights.best.hdf5', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1326 samples, validate on 569 samples\n",
      "Epoch 1/20\n",
      "1312/1326 [============================>.] - ETA: 0s - loss: 3.6210 - score: nan - categorical_accuracy: 0.0671Epoch 00001: val_loss improved from inf to 3.38540, saving model to consonantweights.best.hdf5\n",
      "1326/1326 [==============================] - 12s 9ms/step - loss: 3.6175 - score: nan - categorical_accuracy: 0.0679 - val_loss: 3.3854 - val_score: nan - val_categorical_accuracy: 0.0914\n",
      "Epoch 2/20\n",
      "1312/1326 [============================>.] - ETA: 0s - loss: 3.4257 - score: nan - categorical_accuracy: 0.0938Epoch 00002: val_loss improved from 3.38540 to 3.28049, saving model to consonantweights.best.hdf5\n",
      "1326/1326 [==============================] - 12s 9ms/step - loss: 3.4242 - score: nan - categorical_accuracy: 0.0950 - val_loss: 3.2805 - val_score: nan - val_categorical_accuracy: 0.1301\n",
      "Epoch 3/20\n",
      "1312/1326 [============================>.] - ETA: 0s - loss: 3.1549 - score: nan - categorical_accuracy: 0.1799Epoch 00003: val_loss improved from 3.28049 to 2.78001, saving model to consonantweights.best.hdf5\n",
      "1326/1326 [==============================] - 12s 9ms/step - loss: 3.1483 - score: nan - categorical_accuracy: 0.1817 - val_loss: 2.7800 - val_score: nan - val_categorical_accuracy: 0.2953\n",
      "Epoch 4/20\n",
      "1312/1326 [============================>.] - ETA: 0s - loss: 2.5788 - score: nan - categorical_accuracy: 0.3468Epoch 00004: val_loss improved from 2.78001 to 2.31790, saving model to consonantweights.best.hdf5\n",
      "1326/1326 [==============================] - 12s 9ms/step - loss: 2.5761 - score: nan - categorical_accuracy: 0.3484 - val_loss: 2.3179 - val_score: 0.1959 - val_categorical_accuracy: 0.4148\n",
      "Epoch 5/20\n",
      "1312/1326 [============================>.] - ETA: 0s - loss: 2.0574 - score: 0.3404 - categorical_accuracy: 0.4688Epoch 00005: val_loss improved from 2.31790 to 1.91696, saving model to consonantweights.best.hdf5\n",
      "1326/1326 [==============================] - 13s 9ms/step - loss: 2.0570 - score: 0.3394 - categorical_accuracy: 0.4691 - val_loss: 1.9170 - val_score: 0.4015 - val_categorical_accuracy: 0.5149\n",
      "Epoch 6/20\n",
      "1312/1326 [============================>.] - ETA: 0s - loss: 1.6746 - score: 0.4797 - categorical_accuracy: 0.5755Epoch 00006: val_loss improved from 1.91696 to 1.58462, saving model to consonantweights.best.hdf5\n",
      "1326/1326 [==============================] - 13s 10ms/step - loss: 1.6797 - score: 0.4773 - categorical_accuracy: 0.5724 - val_loss: 1.5846 - val_score: 0.5078 - val_categorical_accuracy: 0.6292\n",
      "Epoch 7/20\n",
      "1312/1326 [============================>.] - ETA: 0s - loss: 1.3858 - score: 0.5601 - categorical_accuracy: 0.6517Epoch 00007: val_loss improved from 1.58462 to 1.48308, saving model to consonantweights.best.hdf5\n",
      "1326/1326 [==============================] - 13s 10ms/step - loss: 1.3853 - score: 0.5605 - categorical_accuracy: 0.6516 - val_loss: 1.4831 - val_score: 0.5716 - val_categorical_accuracy: 0.6274\n",
      "Epoch 8/20\n",
      "1312/1326 [============================>.] - ETA: 0s - loss: 1.1662 - score: 0.6253 - categorical_accuracy: 0.7020Epoch 00008: val_loss improved from 1.48308 to 1.32236, saving model to consonantweights.best.hdf5\n",
      "1326/1326 [==============================] - 12s 9ms/step - loss: 1.1638 - score: 0.6266 - categorical_accuracy: 0.7029 - val_loss: 1.3224 - val_score: 0.6246 - val_categorical_accuracy: 0.6678\n",
      "Epoch 9/20\n",
      "1312/1326 [============================>.] - ETA: 0s - loss: 0.9688 - score: 0.7029 - categorical_accuracy: 0.7675Epoch 00009: val_loss improved from 1.32236 to 1.23426, saving model to consonantweights.best.hdf5\n",
      "1326/1326 [==============================] - 13s 10ms/step - loss: 0.9736 - score: 0.7022 - categorical_accuracy: 0.7670 - val_loss: 1.2343 - val_score: 0.6556 - val_categorical_accuracy: 0.6924\n",
      "Epoch 10/20\n",
      "1312/1326 [============================>.] - ETA: 0s - loss: 0.8331 - score: 0.7490 - categorical_accuracy: 0.7927Epoch 00010: val_loss improved from 1.23426 to 1.15529, saving model to consonantweights.best.hdf5\n",
      "1326/1326 [==============================] - 12s 9ms/step - loss: 0.8311 - score: 0.7495 - categorical_accuracy: 0.7934 - val_loss: 1.1553 - val_score: 0.6710 - val_categorical_accuracy: 0.7047\n",
      "Epoch 11/20\n",
      "1312/1326 [============================>.] - ETA: 0s - loss: 0.6955 - score: 0.7899 - categorical_accuracy: 0.8186Epoch 00011: val_loss improved from 1.15529 to 1.14719, saving model to consonantweights.best.hdf5\n",
      "1326/1326 [==============================] - 13s 10ms/step - loss: 0.6967 - score: 0.7894 - categorical_accuracy: 0.8183 - val_loss: 1.1472 - val_score: 0.6719 - val_categorical_accuracy: 0.6837\n",
      "Epoch 12/20\n",
      "1312/1326 [============================>.] - ETA: 0s - loss: 0.6269 - score: 0.8067 - categorical_accuracy: 0.8438Epoch 00012: val_loss improved from 1.14719 to 1.07511, saving model to consonantweights.best.hdf5\n",
      "1326/1326 [==============================] - 14s 11ms/step - loss: 0.6283 - score: 0.8061 - categorical_accuracy: 0.8431 - val_loss: 1.0751 - val_score: 0.6977 - val_categorical_accuracy: 0.7135\n",
      "Epoch 13/20\n",
      "1312/1326 [============================>.] - ETA: 0s - loss: 0.5419 - score: 0.8386 - categorical_accuracy: 0.8666Epoch 00013: val_loss improved from 1.07511 to 1.01915, saving model to consonantweights.best.hdf5\n",
      "1326/1326 [==============================] - 13s 10ms/step - loss: 0.5410 - score: 0.8382 - categorical_accuracy: 0.8665 - val_loss: 1.0192 - val_score: 0.7091 - val_categorical_accuracy: 0.7276\n",
      "Epoch 14/20\n",
      "1312/1326 [============================>.] - ETA: 0s - loss: 0.4383 - score: 0.8734 - categorical_accuracy: 0.9116Epoch 00014: val_loss did not improve\n",
      "1326/1326 [==============================] - 12s 9ms/step - loss: 0.4394 - score: 0.8731 - categorical_accuracy: 0.9110 - val_loss: 1.0395 - val_score: 0.7167 - val_categorical_accuracy: 0.7399\n",
      "Epoch 15/20\n",
      "1312/1326 [============================>.] - ETA: 0s - loss: 0.3846 - score: 0.8975 - categorical_accuracy: 0.9230Epoch 00015: val_loss improved from 1.01915 to 1.00281, saving model to consonantweights.best.hdf5\n",
      "1326/1326 [==============================] - 12s 9ms/step - loss: 0.3873 - score: 0.8953 - categorical_accuracy: 0.9216 - val_loss: 1.0028 - val_score: 0.7162 - val_categorical_accuracy: 0.7241\n",
      "Epoch 16/20\n",
      "1312/1326 [============================>.] - ETA: 0s - loss: 0.3371 - score: 0.9092 - categorical_accuracy: 0.9306Epoch 00016: val_loss improved from 1.00281 to 0.96825, saving model to consonantweights.best.hdf5\n",
      "1326/1326 [==============================] - 13s 10ms/step - loss: 0.3384 - score: 0.9085 - categorical_accuracy: 0.9299 - val_loss: 0.9682 - val_score: 0.7279 - val_categorical_accuracy: 0.7399\n",
      "Epoch 17/20\n",
      "1312/1326 [============================>.] - ETA: 0s - loss: 0.3070 - score: 0.9234 - categorical_accuracy: 0.9489Epoch 00017: val_loss did not improve\n",
      "1326/1326 [==============================] - 13s 10ms/step - loss: 0.3070 - score: 0.9238 - categorical_accuracy: 0.9487 - val_loss: 0.9703 - val_score: 0.7311 - val_categorical_accuracy: 0.7399\n",
      "Epoch 18/20\n",
      "1312/1326 [============================>.] - ETA: 0s - loss: 0.2621 - score: 0.9353 - categorical_accuracy: 0.9543Epoch 00018: val_loss improved from 0.96825 to 0.95513, saving model to consonantweights.best.hdf5\n",
      "1326/1326 [==============================] - 13s 10ms/step - loss: 0.2613 - score: 0.9360 - categorical_accuracy: 0.9548 - val_loss: 0.9551 - val_score: 0.7431 - val_categorical_accuracy: 0.7417\n",
      "Epoch 19/20\n",
      "1312/1326 [============================>.] - ETA: 0s - loss: 0.2381 - score: 0.9442 - categorical_accuracy: 0.9611Epoch 00019: val_loss improved from 0.95513 to 0.95097, saving model to consonantweights.best.hdf5\n",
      "1326/1326 [==============================] - 13s 10ms/step - loss: 0.2419 - score: 0.9440 - categorical_accuracy: 0.9600 - val_loss: 0.9510 - val_score: 0.7500 - val_categorical_accuracy: 0.7504\n",
      "Epoch 20/20\n",
      "1312/1326 [============================>.] - ETA: 0s - loss: 0.2256 - score: 0.9450 - categorical_accuracy: 0.9596Epoch 00020: val_loss did not improve\n",
      "1326/1326 [==============================] - 14s 10ms/step - loss: 0.2242 - score: 0.9456 - categorical_accuracy: 0.9600 - val_loss: 0.9530 - val_score: 0.7483 - val_categorical_accuracy: 0.7469\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1fb0531898>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,epochs=20,batch_size=32,callbacks=[checkpointer],validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1326 samples, validate on 569 samples\n",
      "Epoch 1/30\n",
      "1312/1326 [============================>.] - ETA: 0s - loss: 0.1648 - score: 0.9640 - categorical_accuracy: 0.9779Epoch 00001: val_loss improved from 0.95097 to 0.94571, saving model to consonantweights.best.hdf5\n",
      "1326/1326 [==============================] - 16s 12ms/step - loss: 0.1645 - score: 0.9640 - categorical_accuracy: 0.9781 - val_loss: 0.9457 - val_score: 0.7535 - val_categorical_accuracy: 0.7487\n",
      "Epoch 2/30\n",
      "1312/1326 [============================>.] - ETA: 0s - loss: 0.1514 - score: 0.9698 - categorical_accuracy: 0.9840Epoch 00002: val_loss improved from 0.94571 to 0.94564, saving model to consonantweights.best.hdf5\n",
      "1326/1326 [==============================] - 15s 11ms/step - loss: 0.1518 - score: 0.9697 - categorical_accuracy: 0.9842 - val_loss: 0.9456 - val_score: 0.7598 - val_categorical_accuracy: 0.7469\n",
      "Epoch 3/30\n",
      "1312/1326 [============================>.] - ETA: 0s - loss: 0.1420 - score: 0.9746 - categorical_accuracy: 0.9817Epoch 00003: val_loss improved from 0.94564 to 0.94028, saving model to consonantweights.best.hdf5\n",
      "1326/1326 [==============================] - 14s 10ms/step - loss: 0.1428 - score: 0.9745 - categorical_accuracy: 0.9819 - val_loss: 0.9403 - val_score: 0.7535 - val_categorical_accuracy: 0.7469\n",
      "Epoch 4/30\n",
      "1312/1326 [============================>.] - ETA: 0s - loss: 0.1360 - score: 0.9706 - categorical_accuracy: 0.9840Epoch 00004: val_loss improved from 0.94028 to 0.93992, saving model to consonantweights.best.hdf5\n",
      "1326/1326 [==============================] - 14s 10ms/step - loss: 0.1352 - score: 0.9709 - categorical_accuracy: 0.9842 - val_loss: 0.9399 - val_score: 0.7544 - val_categorical_accuracy: 0.7504\n",
      "Epoch 5/30\n",
      "1312/1326 [============================>.] - ETA: 0s - loss: 0.1255 - score: 0.9808 - categorical_accuracy: 0.9855Epoch 00005: val_loss did not improve\n",
      "1326/1326 [==============================] - 13s 10ms/step - loss: 0.1252 - score: 0.9810 - categorical_accuracy: 0.9857 - val_loss: 0.9419 - val_score: 0.7558 - val_categorical_accuracy: 0.7540\n",
      "Epoch 6/30\n",
      "1312/1326 [============================>.] - ETA: 0s - loss: 0.1261 - score: 0.9755 - categorical_accuracy: 0.9825Epoch 00006: val_loss improved from 0.93992 to 0.93955, saving model to consonantweights.best.hdf5\n",
      "1326/1326 [==============================] - 15s 12ms/step - loss: 0.1265 - score: 0.9757 - categorical_accuracy: 0.9827 - val_loss: 0.9396 - val_score: 0.7590 - val_categorical_accuracy: 0.7504\n",
      "Epoch 7/30\n",
      "1312/1326 [============================>.] - ETA: 0s - loss: 0.1072 - score: 0.9883 - categorical_accuracy: 0.9939Epoch 00007: val_loss improved from 0.93955 to 0.93609, saving model to consonantweights.best.hdf5\n",
      "1326/1326 [==============================] - 17s 13ms/step - loss: 0.1077 - score: 0.9880 - categorical_accuracy: 0.9932 - val_loss: 0.9361 - val_score: 0.7606 - val_categorical_accuracy: 0.7575\n",
      "Epoch 8/30\n",
      "1312/1326 [============================>.] - ETA: 0s - loss: 0.1066 - score: 0.9832 - categorical_accuracy: 0.9863Epoch 00008: val_loss did not improve\n",
      "1326/1326 [==============================] - 14s 10ms/step - loss: 0.1057 - score: 0.9834 - categorical_accuracy: 0.9864 - val_loss: 0.9390 - val_score: 0.7609 - val_categorical_accuracy: 0.7645\n",
      "Epoch 9/30\n",
      "1312/1326 [============================>.] - ETA: 0s - loss: 0.1053 - score: 0.9876 - categorical_accuracy: 0.9893Epoch 00009: val_loss did not improve\n",
      "1326/1326 [==============================] - 20s 15ms/step - loss: 0.1050 - score: 0.9877 - categorical_accuracy: 0.9894 - val_loss: 0.9410 - val_score: 0.7614 - val_categorical_accuracy: 0.7504\n",
      "Epoch 10/30\n",
      "1312/1326 [============================>.] - ETA: 0s - loss: 0.0972 - score: 0.9852 - categorical_accuracy: 0.9931Epoch 00010: val_loss did not improve\n",
      "1326/1326 [==============================] - 19s 15ms/step - loss: 0.0966 - score: 0.9853 - categorical_accuracy: 0.9932 - val_loss: 0.9454 - val_score: 0.7567 - val_categorical_accuracy: 0.7540\n",
      "Epoch 11/30\n",
      "1312/1326 [============================>.] - ETA: 0s - loss: 0.0958 - score: 0.9879 - categorical_accuracy: 0.9947Epoch 00011: val_loss did not improve\n",
      "1326/1326 [==============================] - 19s 15ms/step - loss: 0.0954 - score: 0.9880 - categorical_accuracy: 0.9947 - val_loss: 0.9387 - val_score: 0.7623 - val_categorical_accuracy: 0.7592\n",
      "Epoch 12/30\n",
      "1312/1326 [============================>.] - ETA: 0s - loss: 0.0921 - score: 0.9883 - categorical_accuracy: 0.9939Epoch 00012: val_loss did not improve\n",
      "1326/1326 [==============================] - 20s 15ms/step - loss: 0.0925 - score: 0.9885 - categorical_accuracy: 0.9940 - val_loss: 0.9433 - val_score: 0.7633 - val_categorical_accuracy: 0.7487\n",
      "Epoch 13/30\n",
      "1312/1326 [============================>.] - ETA: 0s - loss: 0.0898 - score: 0.9875 - categorical_accuracy: 0.9916Epoch 00013: val_loss did not improve\n",
      "1326/1326 [==============================] - 18s 13ms/step - loss: 0.0895 - score: 0.9877 - categorical_accuracy: 0.9917 - val_loss: 0.9433 - val_score: 0.7679 - val_categorical_accuracy: 0.7504\n",
      "Epoch 14/30\n",
      "1312/1326 [============================>.] - ETA: 0s - loss: 0.0893 - score: 0.9884 - categorical_accuracy: 0.9909Epoch 00014: val_loss did not improve\n",
      "1326/1326 [==============================] - 20s 15ms/step - loss: 0.0890 - score: 0.9885 - categorical_accuracy: 0.9910 - val_loss: 0.9471 - val_score: 0.7656 - val_categorical_accuracy: 0.7504\n",
      "Epoch 15/30\n",
      "1312/1326 [============================>.] - ETA: 0s - loss: 0.0843 - score: 0.9890 - categorical_accuracy: 0.9901Epoch 00015: val_loss did not improve\n",
      "1326/1326 [==============================] - 20s 15ms/step - loss: 0.0839 - score: 0.9892 - categorical_accuracy: 0.9902 - val_loss: 0.9519 - val_score: 0.7597 - val_categorical_accuracy: 0.7522\n",
      "Epoch 16/30\n",
      "1312/1326 [============================>.] - ETA: 0s - loss: 0.0817 - score: 0.9895 - categorical_accuracy: 0.9931Epoch 00016: val_loss did not improve\n",
      "1326/1326 [==============================] - 20s 15ms/step - loss: 0.0816 - score: 0.9896 - categorical_accuracy: 0.9932 - val_loss: 0.9432 - val_score: 0.7630 - val_categorical_accuracy: 0.7540\n",
      "Epoch 17/30\n",
      "1312/1326 [============================>.] - ETA: 0s - loss: 0.0760 - score: 0.9914 - categorical_accuracy: 0.9924Epoch 00017: val_loss did not improve\n",
      "1326/1326 [==============================] - 23s 18ms/step - loss: 0.0757 - score: 0.9915 - categorical_accuracy: 0.9925 - val_loss: 0.9422 - val_score: 0.7645 - val_categorical_accuracy: 0.7557\n",
      "Epoch 18/30\n",
      "1312/1326 [============================>.] - ETA: 0s - loss: 0.0855 - score: 0.9867 - categorical_accuracy: 0.9886Epoch 00018: val_loss did not improve\n",
      "1326/1326 [==============================] - 22s 17ms/step - loss: 0.0864 - score: 0.9861 - categorical_accuracy: 0.9879 - val_loss: 0.9398 - val_score: 0.7621 - val_categorical_accuracy: 0.7557\n",
      "Epoch 19/30\n",
      "1312/1326 [============================>.] - ETA: 0s - loss: 0.0782 - score: 0.9923 - categorical_accuracy: 0.9939Epoch 00019: val_loss did not improve\n",
      "1326/1326 [==============================] - 21s 15ms/step - loss: 0.0781 - score: 0.9923 - categorical_accuracy: 0.9940 - val_loss: 0.9403 - val_score: 0.7624 - val_categorical_accuracy: 0.7540\n",
      "Epoch 20/30\n",
      "1312/1326 [============================>.] - ETA: 0s - loss: 0.0744 - score: 0.9915 - categorical_accuracy: 0.9939Epoch 00020: val_loss did not improve\n",
      "1326/1326 [==============================] - 22s 17ms/step - loss: 0.0740 - score: 0.9916 - categorical_accuracy: 0.9940 - val_loss: 0.9426 - val_score: 0.7654 - val_categorical_accuracy: 0.7575\n",
      "Epoch 21/30\n",
      "1312/1326 [============================>.] - ETA: 0s - loss: 0.0695 - score: 0.9918 - categorical_accuracy: 0.9970Epoch 00021: val_loss did not improve\n",
      "1326/1326 [==============================] - 16s 12ms/step - loss: 0.0691 - score: 0.9919 - categorical_accuracy: 0.9970 - val_loss: 0.9395 - val_score: 0.7708 - val_categorical_accuracy: 0.7540\n",
      "Epoch 22/30\n",
      "1312/1326 [============================>.] - ETA: 0s - loss: 0.0681 - score: 0.9931 - categorical_accuracy: 0.9970Epoch 00022: val_loss did not improve\n",
      "1326/1326 [==============================] - 14s 11ms/step - loss: 0.0681 - score: 0.9931 - categorical_accuracy: 0.9970 - val_loss: 0.9420 - val_score: 0.7706 - val_categorical_accuracy: 0.7610\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/30\n",
      "1312/1326 [============================>.] - ETA: 0s - loss: 0.0655 - score: 0.9934 - categorical_accuracy: 0.9962Epoch 00023: val_loss did not improve\n",
      "1326/1326 [==============================] - 15s 11ms/step - loss: 0.0658 - score: 0.9935 - categorical_accuracy: 0.9962 - val_loss: 0.9373 - val_score: 0.7666 - val_categorical_accuracy: 0.7592\n",
      "Epoch 24/30\n",
      "1312/1326 [============================>.] - ETA: 0s - loss: 0.0625 - score: 0.9946 - categorical_accuracy: 0.9939Epoch 00024: val_loss did not improve\n",
      "1326/1326 [==============================] - 15s 11ms/step - loss: 0.0626 - score: 0.9946 - categorical_accuracy: 0.9940 - val_loss: 0.9382 - val_score: 0.7703 - val_categorical_accuracy: 0.7645\n",
      "Epoch 25/30\n",
      "1312/1326 [============================>.] - ETA: 0s - loss: 0.0659 - score: 0.9907 - categorical_accuracy: 0.9939Epoch 00025: val_loss did not improve\n",
      "1326/1326 [==============================] - 17s 13ms/step - loss: 0.0656 - score: 0.9908 - categorical_accuracy: 0.9940 - val_loss: 0.9448 - val_score: 0.7684 - val_categorical_accuracy: 0.7575\n",
      "Epoch 26/30\n",
      "1312/1326 [============================>.] - ETA: 0s - loss: 0.0627 - score: 0.9922 - categorical_accuracy: 0.9924Epoch 00026: val_loss did not improve\n",
      "1326/1326 [==============================] - 15s 12ms/step - loss: 0.0627 - score: 0.9919 - categorical_accuracy: 0.9925 - val_loss: 0.9416 - val_score: 0.7684 - val_categorical_accuracy: 0.7575\n",
      "Epoch 27/30\n",
      "1312/1326 [============================>.] - ETA: 0s - loss: 0.0593 - score: 0.9957 - categorical_accuracy: 0.9977Epoch 00027: val_loss did not improve\n",
      "1326/1326 [==============================] - 14s 11ms/step - loss: 0.0591 - score: 0.9958 - categorical_accuracy: 0.9977 - val_loss: 0.9400 - val_score: 0.7704 - val_categorical_accuracy: 0.7522\n",
      "Epoch 28/30\n",
      "1312/1326 [============================>.] - ETA: 0s - loss: 0.0561 - score: 0.9942 - categorical_accuracy: 0.9954Epoch 00028: val_loss did not improve\n",
      "1326/1326 [==============================] - 15s 11ms/step - loss: 0.0563 - score: 0.9943 - categorical_accuracy: 0.9955 - val_loss: 0.9391 - val_score: 0.7670 - val_categorical_accuracy: 0.7540\n",
      "Epoch 29/30\n",
      "1312/1326 [============================>.] - ETA: 0s - loss: 0.0588 - score: 0.9931 - categorical_accuracy: 0.9954Epoch 00029: val_loss did not improve\n",
      "1326/1326 [==============================] - 14s 11ms/step - loss: 0.0587 - score: 0.9931 - categorical_accuracy: 0.9955 - val_loss: 0.9444 - val_score: 0.7665 - val_categorical_accuracy: 0.7557\n",
      "Epoch 30/30\n",
      "1312/1326 [============================>.] - ETA: 0s - loss: 0.0516 - score: 0.9950 - categorical_accuracy: 0.9962Epoch 00030: val_loss did not improve\n",
      "1326/1326 [==============================] - 14s 10ms/step - loss: 0.0532 - score: 0.9943 - categorical_accuracy: 0.9955 - val_loss: 0.9465 - val_score: 0.7642 - val_categorical_accuracy: 0.7575\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1f93f6d6d8>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_adam = keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(optimizer=new_adam,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=[f1_score(theta=0.5), 'categorical_accuracy'])\n",
    "model.fit(X_train,y_train,epochs=30,batch_size=32,callbacks = [checkpointer],validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matra Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_matra = np.array(matra_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "le_matra = LabelEncoder()\n",
    "le_matra.fit(matra_class)\n",
    "y_matra_labeled = le_matra.transform(matra_class)\n",
    "y_matra_train = np_utils.to_categorical(y_matra_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "matra_dict = {i:le_matra.classes_[i] for i in range(len(le_matra.classes_))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_matra_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(16,(2,2),input_shape=(X_train[0].shape),activation = 'relu'))\n",
    "model.add(Conv2D(32,(2,2),activation = 'relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(16,(2,2),activation = 'relu'))\n",
    "model.add(Conv2D(32,(2,2),activation = 'relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(64,(2,2),activation = 'relu'))\n",
    "model.add(Conv2D(64,(2,2),activation = 'relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256,activation = 'sigmoid'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(len(set(matra_class)),activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=[f1_score(theta=0.5), 'categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "checkpointer_matra = ModelCheckpoint(filepath='matraweights.best.hdf5', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1326 samples, validate on 569 samples\n",
      "Epoch 1/10\n",
      "1312/1326 [============================>.] - ETA: 0s - loss: 2.1115 - score: nan - categorical_accuracy: 0.4002Epoch 00001: val_loss improved from inf to 1.81128, saving model to matraweights.best.hdf5\n",
      "1326/1326 [==============================] - 13s 10ms/step - loss: 2.1072 - score: nan - categorical_accuracy: 0.4012 - val_loss: 1.8113 - val_score: 0.4242 - val_categorical_accuracy: 0.4675\n",
      "Epoch 2/10\n",
      "1312/1326 [============================>.] - ETA: 0s - loss: 1.5323 - score: 0.5023 - categorical_accuracy: 0.5412Epoch 00002: val_loss improved from 1.81128 to 1.14860, saving model to matraweights.best.hdf5\n",
      "1326/1326 [==============================] - 11s 9ms/step - loss: 1.5304 - score: 0.5034 - categorical_accuracy: 0.5415 - val_loss: 1.1486 - val_score: 0.6420 - val_categorical_accuracy: 0.6503\n",
      "Epoch 3/10\n",
      "1312/1326 [============================>.] - ETA: 0s - loss: 1.1084 - score: 0.6663 - categorical_accuracy: 0.6745Epoch 00003: val_loss improved from 1.14860 to 0.89951, saving model to matraweights.best.hdf5\n",
      "1326/1326 [==============================] - 11s 9ms/step - loss: 1.1078 - score: 0.6657 - categorical_accuracy: 0.6757 - val_loss: 0.8995 - val_score: 0.7209 - val_categorical_accuracy: 0.7346\n",
      "Epoch 4/10\n",
      "1312/1326 [============================>.] - ETA: 0s - loss: 0.9332 - score: 0.7144 - categorical_accuracy: 0.7149Epoch 00004: val_loss improved from 0.89951 to 0.79754, saving model to matraweights.best.hdf5\n",
      "1326/1326 [==============================] - 11s 9ms/step - loss: 0.9289 - score: 0.7162 - categorical_accuracy: 0.7172 - val_loss: 0.7975 - val_score: 0.7286 - val_categorical_accuracy: 0.7540\n",
      "Epoch 5/10\n",
      "1312/1326 [============================>.] - ETA: 0s - loss: 0.8102 - score: 0.7407 - categorical_accuracy: 0.7477Epoch 00005: val_loss improved from 0.79754 to 0.78402, saving model to matraweights.best.hdf5\n",
      "1326/1326 [==============================] - 11s 9ms/step - loss: 0.8040 - score: 0.7427 - categorical_accuracy: 0.7496 - val_loss: 0.7840 - val_score: 0.7479 - val_categorical_accuracy: 0.7645\n",
      "Epoch 6/10\n",
      "1312/1326 [============================>.] - ETA: 0s - loss: 0.6933 - score: 0.7823 - categorical_accuracy: 0.7889Epoch 00006: val_loss improved from 0.78402 to 0.62783, saving model to matraweights.best.hdf5\n",
      "1326/1326 [==============================] - 11s 9ms/step - loss: 0.7017 - score: 0.7780 - categorical_accuracy: 0.7851 - val_loss: 0.6278 - val_score: 0.8069 - val_categorical_accuracy: 0.8207\n",
      "Epoch 7/10\n",
      "1312/1326 [============================>.] - ETA: 0s - loss: 0.6275 - score: 0.7969 - categorical_accuracy: 0.7995Epoch 00007: val_loss improved from 0.62783 to 0.62147, saving model to matraweights.best.hdf5\n",
      "1326/1326 [==============================] - 11s 9ms/step - loss: 0.6312 - score: 0.7955 - categorical_accuracy: 0.7986 - val_loss: 0.6215 - val_score: 0.8158 - val_categorical_accuracy: 0.8243\n",
      "Epoch 8/10\n",
      "1312/1326 [============================>.] - ETA: 0s - loss: 0.5965 - score: 0.8087 - categorical_accuracy: 0.8117Epoch 00008: val_loss improved from 0.62147 to 0.56975, saving model to matraweights.best.hdf5\n",
      "1326/1326 [==============================] - 11s 9ms/step - loss: 0.5943 - score: 0.8096 - categorical_accuracy: 0.8130 - val_loss: 0.5698 - val_score: 0.8390 - val_categorical_accuracy: 0.8418\n",
      "Epoch 9/10\n",
      "1312/1326 [============================>.] - ETA: 0s - loss: 0.4717 - score: 0.8538 - categorical_accuracy: 0.8666Epoch 00009: val_loss improved from 0.56975 to 0.55987, saving model to matraweights.best.hdf5\n",
      "1326/1326 [==============================] - 12s 9ms/step - loss: 0.4744 - score: 0.8536 - categorical_accuracy: 0.8658 - val_loss: 0.5599 - val_score: 0.8361 - val_categorical_accuracy: 0.8348\n",
      "Epoch 10/10\n",
      "1312/1326 [============================>.] - ETA: 0s - loss: 0.4300 - score: 0.8632 - categorical_accuracy: 0.8704Epoch 00010: val_loss improved from 0.55987 to 0.53479, saving model to matraweights.best.hdf5\n",
      "1326/1326 [==============================] - 12s 9ms/step - loss: 0.4294 - score: 0.8635 - categorical_accuracy: 0.8703 - val_loss: 0.5348 - val_score: 0.8490 - val_categorical_accuracy: 0.8453\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1f931edc50>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_matra_train,epochs=10,batch_size=32,callbacks=[checkpointer_matra],validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_adam = keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(optimizer=new_adam,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=[f1_score(theta=0.5), 'categorical_accuracy'])\n",
    "model.fit(X_train,y_matra_train,epochs=30,batch_size=32,callbacks = [checkpointer_matra],validation_split=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dot Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_dot = np.array(dot_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "le_dot = LabelEncoder()\n",
    "le_dot.fit(dot_class)\n",
    "y_dot_labeled = le_dot.transform(dot_class)\n",
    "y_dot_train = np_utils.to_categorical(y_dot_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dot_dict = {i:le_dot.classes_[i] for i in range(len(le_dot.classes_))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "complete_dicts = [base_dict,matra_dict,dot_dict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"dicts.txt\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(complete_dicts, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_dot_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(16,(2,2),input_shape=(X_train[0].shape),activation = 'relu'))\n",
    "model.add(Conv2D(32,(2,2),activation = 'relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(64,(2,2),activation = 'relu'))\n",
    "model.add(Conv2D(64,(2,2),activation = 'relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256,activation = 'sigmoid'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(len(set(dot_class)),activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=[f1_score(theta=0.5), 'categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "checkpointer_dot = ModelCheckpoint(filepath='dotweights.best.hdf5', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1326 samples, validate on 569 samples\n",
      "Epoch 1/3\n",
      "1312/1326 [============================>.] - ETA: 0s - loss: 0.3084 - score: 0.9238 - categorical_accuracy: 0.9238Epoch 00001: val_loss improved from inf to 0.28202, saving model to dotweights.best.hdf5\n",
      "1326/1326 [==============================] - 20s 15ms/step - loss: 0.3076 - score: 0.9238 - categorical_accuracy: 0.9238 - val_loss: 0.2820 - val_score: 0.9174 - val_categorical_accuracy: 0.9174\n",
      "Epoch 2/3\n",
      "1312/1326 [============================>.] - ETA: 0s - loss: 0.2504 - score: 0.9306 - categorical_accuracy: 0.9306Epoch 00002: val_loss improved from 0.28202 to 0.22692, saving model to dotweights.best.hdf5\n",
      "1326/1326 [==============================] - 19s 15ms/step - loss: 0.2486 - score: 0.9314 - categorical_accuracy: 0.9314 - val_loss: 0.2269 - val_score: 0.9209 - val_categorical_accuracy: 0.9209\n",
      "Epoch 3/3\n",
      "1312/1326 [============================>.] - ETA: 0s - loss: 0.1922 - score: 0.9352 - categorical_accuracy: 0.9352Epoch 00003: val_loss improved from 0.22692 to 0.20226, saving model to dotweights.best.hdf5\n",
      "1326/1326 [==============================] - 19s 14ms/step - loss: 0.1914 - score: 0.9359 - categorical_accuracy: 0.9359 - val_loss: 0.2023 - val_score: 0.9192 - val_categorical_accuracy: 0.9192\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1f938c08d0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_dot_train,epochs=3,batch_size=32,callbacks = [checkpointer_dot],validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1895"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=[f1_score(theta=0.5), 'categorical_accuracy'])\n",
    "model.fit(X_train,y_matra_train,epochs=30,batch_size=32,callbacks = [checkpointer_dot],validation_split=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Half-consonant model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "half_images = np.array(half_images)\n",
    "X_half = np.reshape(np.array(images), (-1, 64*32))\n",
    "y_half = np.array(base_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "le_half = LabelEncoder()\n",
    "le_half.fit(base_class)\n",
    "y_half_labeled = le_half.transform(base_class)\n",
    "y_half_train = np_utils.to_categorical(y_half_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1895, 53)\n",
      "(1895, 64, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "print(y_half_train.shape)\n",
    "X_half_train = np.reshape(half_images,(-1,64,32,1))\n",
    "print(X_half_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(16,(2,2),input_shape=(X_half_train[0].shape),activation = 'relu'))\n",
    "model.add(Conv2D(32,(2,2),activation = 'relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(16,(2,2),activation = 'relu'))\n",
    "model.add(Conv2D(32,(2,2),activation = 'relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(64,(2,2),activation = 'relu'))\n",
    "model.add(Conv2D(64,(2,2),activation = 'relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256,activation = 'sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(set(base_class)),activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=[f1_score(theta=0.5), 'categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1326 samples, validate on 569 samples\n",
      "Epoch 1/30\n",
      "1326/1326 [==============================] - 7s 5ms/step - loss: 3.6615 - score: nan - categorical_accuracy: 0.0664 - val_loss: 3.3703 - val_score: nan - val_categorical_accuracy: 0.0914\n",
      "Epoch 2/30\n",
      "1326/1326 [==============================] - 6s 4ms/step - loss: 3.4355 - score: nan - categorical_accuracy: 0.0852 - val_loss: 3.3377 - val_score: nan - val_categorical_accuracy: 0.0914\n",
      "Epoch 3/30\n",
      "1326/1326 [==============================] - 6s 4ms/step - loss: 3.3377 - score: nan - categorical_accuracy: 0.1131 - val_loss: 3.2372 - val_score: nan - val_categorical_accuracy: 0.1617\n",
      "Epoch 4/30\n",
      "1326/1326 [==============================] - 6s 4ms/step - loss: 3.2198 - score: nan - categorical_accuracy: 0.1463 - val_loss: 3.1289 - val_score: nan - val_categorical_accuracy: 0.1564\n",
      "Epoch 5/30\n",
      "1326/1326 [==============================] - 6s 4ms/step - loss: 3.0673 - score: nan - categorical_accuracy: 0.1855 - val_loss: 3.0091 - val_score: nan - val_categorical_accuracy: 0.1986\n",
      "Epoch 6/30\n",
      "1326/1326 [==============================] - 6s 4ms/step - loss: 2.9987 - score: nan - categorical_accuracy: 0.2164 - val_loss: 2.9143 - val_score: nan - val_categorical_accuracy: 0.2443\n",
      "Epoch 7/30\n",
      "1326/1326 [==============================] - 6s 4ms/step - loss: 2.8141 - score: nan - categorical_accuracy: 0.2459 - val_loss: 2.7549 - val_score: nan - val_categorical_accuracy: 0.2724\n",
      "Epoch 8/30\n",
      "1326/1326 [==============================] - 6s 4ms/step - loss: 2.6064 - score: nan - categorical_accuracy: 0.3062 - val_loss: 2.6053 - val_score: nan - val_categorical_accuracy: 0.3111\n",
      "Epoch 9/30\n",
      "1326/1326 [==============================] - 6s 4ms/step - loss: 2.4826 - score: nan - categorical_accuracy: 0.3281 - val_loss: 2.4540 - val_score: 0.1511 - val_categorical_accuracy: 0.3638\n",
      "Epoch 10/30\n",
      "1326/1326 [==============================] - 6s 4ms/step - loss: 2.2969 - score: nan - categorical_accuracy: 0.3816 - val_loss: 2.3727 - val_score: 0.1907 - val_categorical_accuracy: 0.3954\n",
      "Epoch 11/30\n",
      "1326/1326 [==============================] - 6s 4ms/step - loss: 2.1660 - score: 0.2441 - categorical_accuracy: 0.4359 - val_loss: 2.2808 - val_score: 0.2235 - val_categorical_accuracy: 0.3884\n",
      "Epoch 12/30\n",
      "1326/1326 [==============================] - 6s 4ms/step - loss: 2.0114 - score: 0.2813 - categorical_accuracy: 0.4510 - val_loss: 2.1816 - val_score: 0.2798 - val_categorical_accuracy: 0.4236\n",
      "Epoch 13/30\n",
      "1326/1326 [==============================] - 6s 4ms/step - loss: 1.9144 - score: 0.3182 - categorical_accuracy: 0.4789 - val_loss: 2.1296 - val_score: 0.2846 - val_categorical_accuracy: 0.4482\n",
      "Epoch 14/30\n",
      "1326/1326 [==============================] - 6s 4ms/step - loss: 1.7894 - score: 0.3530 - categorical_accuracy: 0.5256 - val_loss: 2.0502 - val_score: 0.3640 - val_categorical_accuracy: 0.4552\n",
      "Epoch 15/30\n",
      "1326/1326 [==============================] - 6s 5ms/step - loss: 1.6826 - score: 0.4133 - categorical_accuracy: 0.5392 - val_loss: 1.9693 - val_score: 0.3990 - val_categorical_accuracy: 0.4833\n",
      "Epoch 16/30\n",
      "1326/1326 [==============================] - 6s 5ms/step - loss: 1.6051 - score: 0.4303 - categorical_accuracy: 0.5468 - val_loss: 1.9349 - val_score: 0.3936 - val_categorical_accuracy: 0.4974\n",
      "Epoch 17/30\n",
      "1326/1326 [==============================] - 6s 5ms/step - loss: 1.4570 - score: 0.4772 - categorical_accuracy: 0.5920 - val_loss: 1.9113 - val_score: 0.4330 - val_categorical_accuracy: 0.4851\n",
      "Epoch 18/30\n",
      "1326/1326 [==============================] - 6s 5ms/step - loss: 1.3988 - score: 0.5029 - categorical_accuracy: 0.6041 - val_loss: 1.8644 - val_score: 0.4327 - val_categorical_accuracy: 0.5062\n",
      "Epoch 19/30\n",
      "1326/1326 [==============================] - 7s 5ms/step - loss: 1.3110 - score: 0.5237 - categorical_accuracy: 0.6365 - val_loss: 1.8208 - val_score: 0.4454 - val_categorical_accuracy: 0.5220\n",
      "Epoch 20/30\n",
      "1326/1326 [==============================] - 6s 4ms/step - loss: 1.2411 - score: 0.5611 - categorical_accuracy: 0.6508 - val_loss: 1.8140 - val_score: 0.4589 - val_categorical_accuracy: 0.5097\n",
      "Epoch 21/30\n",
      "1326/1326 [==============================] - 6s 4ms/step - loss: 1.2014 - score: 0.5695 - categorical_accuracy: 0.6682 - val_loss: 1.7695 - val_score: 0.4658 - val_categorical_accuracy: 0.5466\n",
      "Epoch 22/30\n",
      "1326/1326 [==============================] - 6s 5ms/step - loss: 1.1177 - score: 0.5920 - categorical_accuracy: 0.6931 - val_loss: 1.7498 - val_score: 0.4925 - val_categorical_accuracy: 0.5325\n",
      "Epoch 23/30\n",
      "1326/1326 [==============================] - 6s 4ms/step - loss: 1.0582 - score: 0.6257 - categorical_accuracy: 0.7051 - val_loss: 1.7353 - val_score: 0.4978 - val_categorical_accuracy: 0.5466\n",
      "Epoch 24/30\n",
      "1326/1326 [==============================] - 6s 4ms/step - loss: 0.9876 - score: 0.6552 - categorical_accuracy: 0.7315 - val_loss: 1.7382 - val_score: 0.5055 - val_categorical_accuracy: 0.5466\n",
      "Epoch 25/30\n",
      "1326/1326 [==============================] - 6s 4ms/step - loss: 0.9491 - score: 0.6721 - categorical_accuracy: 0.7436 - val_loss: 1.7207 - val_score: 0.5008 - val_categorical_accuracy: 0.5677\n",
      "Epoch 26/30\n",
      "1326/1326 [==============================] - 6s 4ms/step - loss: 0.8973 - score: 0.6877 - categorical_accuracy: 0.7617 - val_loss: 1.7015 - val_score: 0.5216 - val_categorical_accuracy: 0.5659\n",
      "Epoch 27/30\n",
      "1326/1326 [==============================] - 6s 4ms/step - loss: 0.8725 - score: 0.7022 - categorical_accuracy: 0.7617 - val_loss: 1.6857 - val_score: 0.5187 - val_categorical_accuracy: 0.5624\n",
      "Epoch 28/30\n",
      "1326/1326 [==============================] - 6s 4ms/step - loss: 0.8038 - score: 0.7218 - categorical_accuracy: 0.7753 - val_loss: 1.6919 - val_score: 0.5212 - val_categorical_accuracy: 0.5659\n",
      "Epoch 29/30\n",
      "1326/1326 [==============================] - 6s 4ms/step - loss: 0.7676 - score: 0.7360 - categorical_accuracy: 0.7896 - val_loss: 1.6761 - val_score: 0.5324 - val_categorical_accuracy: 0.5835\n",
      "Epoch 30/30\n",
      "1326/1326 [==============================] - 6s 4ms/step - loss: 0.7351 - score: 0.7564 - categorical_accuracy: 0.7994 - val_loss: 1.6927 - val_score: 0.5298 - val_categorical_accuracy: 0.5659\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9ee9aa4518>"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_half_train,y_half_train,epochs=30,batch_size=32,validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[142, 144, 141, ..., 142, 147, 150],\n",
       "       [149, 148, 147, ..., 143, 147, 150],\n",
       "       [150, 152, 152, ..., 148, 148, 150],\n",
       "       ..., \n",
       "       [144, 146, 146, ..., 158, 155, 151],\n",
       "       [146, 150, 149, ..., 168, 163, 159],\n",
       "       [143, 145, 147, ..., 166, 165, 164]], dtype=uint8)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(os.path.join('','test.png'),0)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blur = cv2.GaussianBlur(img,(9,9),0)# KADD\n",
    "a,img = cv2.threshold(img,127,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)#KEDIT\n",
    "img = pad_resize(img)\n",
    "blur = cv2.GaussianBlur(img,(9,9),0)# KADD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFLgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9ed78972b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img,\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "half_img = np.hsplit(img,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_half = np.reshape(np.array(half_img[0]), (-1, 64*32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_half_train = np.reshape(half_img[0],(-1,64,32,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6])"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(X_half_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAD8CAYAAAB+fLH0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCo7jZLhTcBwnw52C4zgZ7hQcx8n4F03cnQqM7K0tAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1f925964e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "im = plt.imread('ok.png')\n",
    "plt.imshow(im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111, 111, 3)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im[:,:,:3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "im[:,:,3]\n",
    "def rgb2gray(rgb):\n",
    "    return np.dot(rgb[...,:3], [0.299, 0.587, 0.114])\n",
    "image = rgb2gray(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'src' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-191-6cd6ce526bdc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCV_8UC1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myour\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCV_8UC1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'src' is not defined"
     ]
    }
   ],
   "source": [
    "image.shape\n",
    "src.create(rows, cols, CV_8UC1);\n",
    "src = imread(your-file, CV_8UC1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "/io/opencv/modules/imgproc/src/thresh.cpp:1356: error: (-215) src.type() == CV_8UC1 in function threshold\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-190-021d38194dfe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mblur\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGaussianBlur\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblur\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m127\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTHRESH_BINARY\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTHRESH_OTSU\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31merror\u001b[0m: /io/opencv/modules/imgproc/src/thresh.cpp:1356: error: (-215) src.type() == CV_8UC1 in function threshold\n"
     ]
    }
   ],
   "source": [
    "blur = cv2.GaussianBlur(image,(9,9),0)\n",
    "a,img = cv2.threshold(blur,127,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
