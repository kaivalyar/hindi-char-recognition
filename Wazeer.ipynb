{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage import io, morphology, img_as_bool, segmentation\n",
    "from scipy import ndimage as ndi\n",
    "from scipy.ndimage.morphology import binary_fill_holes\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_resize(img):\n",
    "    top = int((224 - img.shape[0])/2)\n",
    "    left = int((224 - img.shape[1])/2)\n",
    "    bottom = 224 - img.shape[0] - top\n",
    "    right = 224 - img.shape[1] - left\n",
    "    img = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=255)\n",
    "    img = img/255.\n",
    "    img = cv2.resize(img, (50,50)) #KADD\n",
    "    return img\n",
    "\n",
    "def skeletonize(img):\n",
    "    size = np.size(img)\n",
    "    skel = np.zeros(img.shape,np.uint8)\n",
    "    img = cv2.bitwise_not(img)\n",
    "#     element = cv2.getStructuringElement(cv2.MORPH_CROSS,(1,1))\n",
    "#     done = 0\n",
    "#     while( done < 1 ):\n",
    "#         eroded = cv2.erode(img,element)\n",
    "#         temp = cv2.dilate(eroded,element)\n",
    "#         temp = cv2.subtract(img,temp)\n",
    "#         skel = cv2.bitwise_or(skel,temp)\n",
    "#         img = eroded.copy()\n",
    "\n",
    "#         zeros = size - cv2.countNonZero(img)\n",
    "#         if zeros==size:#cv2.countNonZero(img) * 1 >= 0:#\n",
    "#             done += 1\n",
    "#     img = skel\n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    erosion = cv2.erode(img,kernel,iterations = 2)\n",
    "    img = cv2.bitwise_not(erosion)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 Done\n",
      "200 Done\n",
      "300 Done\n",
      "400 Done\n",
      "500 Done\n",
      "600 Done\n",
      "700 Done\n",
      "800 Done\n",
      "900 Done\n",
      "1000 Done\n",
      "1100 Done\n",
      "1200 Done\n",
      "1300 Done\n",
      "1400 Done\n",
      "1500 Done\n",
      "1600 Done\n",
      "1700 Done\n",
      "1800 Done\n"
     ]
    }
   ],
   "source": [
    "PATH = '../train_images_modified'\n",
    "images = []\n",
    "base_class = []\n",
    "matra_class = []\n",
    "total_class = []\n",
    "for filename in os.listdir(PATH):\n",
    "    if filename.endswith(\".png\"):\n",
    "        img = cv2.imread(os.path.join(PATH,filename),0)\n",
    "        blur = cv2.GaussianBlur(img,(9,9),0)# KADD\n",
    "        a,img = cv2.threshold(img,127,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)#KEDIT\n",
    "#         plt.imshow(img, cmap='gray')\n",
    "#         plt.show()\n",
    "# #         kernel = np.ones((5,5),np.uint8)\n",
    "#         img = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
    "#         plt.imshow(img, cmap='gray')\n",
    "#         plt.show()\n",
    "        #img = skeletonize(img)\n",
    "        img = pad_resize(img)\n",
    "        blur = cv2.GaussianBlur(img,(9,9),0)# KADD\n",
    "        char_arr = filename[:-4].split('_')[3:]\n",
    "        if(len(char_arr)>0):\n",
    "            images.append(img)\n",
    "            char_arr = [int(i) for i in char_arr]\n",
    "            total_class.append(char_arr)\n",
    "            base = [i for i in char_arr if (i>=2308 and i<=2361) or (i==2384) or (i>=2392 and i<=2401) or (i>=2404 and i!=2416 and i!=2417)]  \n",
    "            base_class.append(base[0])\n",
    "#             if(len(char_arr)>1):          \n",
    "#                 matra_class.append(char_arr[1:])\n",
    "            if len(images)%100==0:\n",
    "                print(\"{} Done\".format(len(images)))\n",
    "            \n",
    "# print(len(images))\n",
    "# print(len(char_class))\n",
    "# print(images[0])\n",
    "# print(char_class[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngQT9P6HNxKAQdTl5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x134b93470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1895\n"
     ]
    }
   ],
   "source": [
    "plt.imshow(images[10],\"gray\")\n",
    "plt.show()\n",
    "print(len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 555,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(base_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.array(images)\n",
    "x_data = np.reshape(np.array(images), (-1, 50*50))\n",
    "y_data = np.array(base_class)\n",
    "\n",
    "df = pd.DataFrame(x_data, y_data)\n",
    "df['LABEL'] = df.index\n",
    "\n",
    "df_no_label = df.drop(columns='LABEL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.metrics import f1_score\n",
    "# from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# #print(df.head())\n",
    "# #print(df_no_label)\n",
    "# #print(df['LABEL'])\n",
    "\n",
    "# X_train,X_val,y_train,y_val = train_test_split(df_no_label, df['LABEL'])\n",
    "\n",
    "# print(X_train.shape)\n",
    "# print(X_val.shape)\n",
    "\n",
    "# clf = RandomForestClassifier(max_features='auto', n_estimators=10, max_depth=20)\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "# scores = cross_val_score(clf, df_no_label, df['LABEL'], cv=3)\n",
    "# print(scores)\n",
    "# scores_f1 = f1_score(clf.predict(X_train),y_train,average='weighted')\n",
    "# print(scores_f1)\n",
    "# scores_f1 = f1_score(clf.predict(X_val),y_val,average='weighted')\n",
    "# print(scores_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(base_class)\n",
    "y_labeled = le.transform(base_class)\n",
    "y_train = np_utils.to_categorical(y_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "\n",
    "# model.add(Dense(256,input_shape=(224*224,),activation = 'sigmoid'))\n",
    "# model.add(Dense(128,activation = 'sigmoid'))\n",
    "# model.add(Dense(128,activation = 'sigmoid'))\n",
    "# model.add(Dense(len(total_char_set),activation = 'sigmoid'))\n",
    "\n",
    "# print(model.summary())\n",
    "# model.compile(optimizer='adam',\n",
    "#               loss='categorical_crossentropy',\n",
    "#               metrics=[f1_score(theta=0.5),'accuracy'])\n",
    "# X_train = X_train.reshape((-1,224*224))\n",
    "# model.fit(X_train,y_train2,epochs=10,batch_size=32,validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1895, 53)\n",
      "(1895, 50, 50, 1)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "x_train = np.reshape(images,(-1,50,50,1))\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Conv2D,MaxPooling2D,Flatten\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16,(3,3),input_shape = (50,50,1),activation = 'relu'))\n",
    "model.add(Conv2D(16,(3,3),activation = 'relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(32,(3,3),activation = 'relu'))\n",
    "model.add(Conv2D(32,(3,3),activation = 'relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256,activation = 'sigmoid'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(len(set(base_class)),activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_29 (Conv2D)           (None, 48, 48, 16)        160       \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 46, 46, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 23, 23, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 21, 21, 32)        4640      \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 19, 19, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 9, 9, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 53)                13621     \n",
      "=================================================================\n",
      "Total params: 161,317\n",
      "Trainable params: 161,317\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "def f1_score(theta):\n",
    "    def score(y_true, y_pred):\n",
    "\n",
    "        y_thresh = K.cast(K.greater(y_pred,theta),K.floatx())\n",
    "\n",
    "        true_pos =  K.sum(y_true * y_thresh)\n",
    "        false_pos = K.sum(y_true * (1. - y_thresh))\n",
    "        false_neg = K.sum((1. - y_true) * y_thresh)\n",
    "\n",
    "        precision = true_pos / (true_pos + false_pos)\n",
    "        recall = true_pos / (true_pos + false_neg)\n",
    "        \n",
    "        f1_score_val = 2 * (precision * recall) / (precision + recall)\n",
    "        return f1_score_val\n",
    "    return score\n",
    "\n",
    "def custom_metric(y_true, y_pred):\n",
    "    return K.cast(K.equal(y_true,\n",
    "                          K.round(y_pred)),\n",
    "                  K.floatx())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=[f1_score(theta=0.5), 'categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1326 samples, validate on 569 samples\n",
      "Epoch 1/10\n",
      "1326/1326 [==============================] - 11s 8ms/step - loss: 3.4834 - score: 0.0856 - categorical_accuracy: 0.0762 - val_loss: 3.5457 - val_score: 0.0837 - val_categorical_accuracy: 0.0879\n",
      "Epoch 2/10\n",
      "1326/1326 [==============================] - 9s 6ms/step - loss: 3.3213 - score: 0.1005 - categorical_accuracy: 0.0973 - val_loss: 3.5792 - val_score: 0.0881 - val_categorical_accuracy: 0.0879\n",
      "Epoch 3/10\n",
      "1326/1326 [==============================] - 9s 6ms/step - loss: 3.2958 - score: 0.1071 - categorical_accuracy: 0.0928 - val_loss: 3.5329 - val_score: 0.0960 - val_categorical_accuracy: 0.0879\n",
      "Epoch 4/10\n",
      "1326/1326 [==============================] - 11s 8ms/step - loss: 3.2870 - score: 0.1076 - categorical_accuracy: 0.1124 - val_loss: 3.4911 - val_score: 0.1082 - val_categorical_accuracy: 0.0879\n",
      "Epoch 5/10\n",
      "1326/1326 [==============================] - 9s 7ms/step - loss: 3.1114 - score: 0.1314 - categorical_accuracy: 0.1154 - val_loss: 3.2262 - val_score: 0.1451 - val_categorical_accuracy: 0.0879\n",
      "Epoch 6/10\n",
      "1312/1326 [============================>.] - ETA: 0s - loss: 2.7257 - score: 0.2381 - categorical_accuracy: 0.1136"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-600-d10c06bc0121>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1648\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1225\u001b[0m                             val_outs = self._test_loop(val_f, val_ins,\n\u001b[1;32m   1226\u001b[0m                                                        \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1227\u001b[0;31m                                                        verbose=0)\n\u001b[0m\u001b[1;32m   1228\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1229\u001b[0m                                 \u001b[0mval_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_test_loop\u001b[0;34m(self, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1368\u001b[0m                     \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1371\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2350\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2351\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2352\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2353\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs=10,batch_size=32,validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.zeros(preds[0].shape)\n",
    "labels[preds[5]>0.5] = 1\n",
    "labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
